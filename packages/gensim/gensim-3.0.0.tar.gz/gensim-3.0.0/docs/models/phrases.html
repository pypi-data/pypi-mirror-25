<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">




<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <!-- Google Tag Manager - JD-20170831 --> 
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-MP366CC');</script>
    <!-- End Google Tag Manager -->

    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta property="description" content="Efficient topic modelling of text semantics in Python." />
    <meta property="og:title" content="gensim: topic modelling for humans" />
    <meta property="og:description" content="Efficient topic modelling in Python" />

    
      <title>gensim: models.phrases – Phrase (collocation) detection</title>

    
  <link rel="stylesheet" href="../_static/css/style.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/jquery.qtip.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/anythingslider.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

    <link rel="shortcut icon" href="../_static/favicon.ico"/>

  </head>

  <body>
    <!-- Google Tag Manager (noscript) - JD-20170831 -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MP366CC"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->

    <div id="topwrap">
      
      <div id="top1">
        <div id="left1">
          <h1 class="h1gensim">
            <img src="../_static/images/logo-gensim_compact.png" alt="gensim logo" title="Gensim - topic modelling for humans" />
          </h1>
        </div>

        <div id="middleright">
          <div id="middle1">
            <div id="gensim"><a href="../index.html"><img src="../_static/images/gensim_compact.png" alt="gensim" title="Gensim home" /></a></div>
            <div id="tagline"><img src="../_static/images/tagline_compact.png" alt="gensim tagline" /></div>
          </div>
          <div id="right1">
            <div class="consulting-banner">
              <h3><a href="http://rare-technologies.com/">Get Expert Help</a></h3>
              <p>• machine learning, NLP, data mining</p>
              <p>• custom SW design, development, optimizations</p>
              <p>• corporate trainings &amp; IT consulting</p>
            </div>
          </div>
        </div>
      </div>
     

      
      <div id="menu">
        <div id="indentation1">
          <ul class="menubuttons">
            <li class="menubutton"><a href="../index.html">Home</a></li>
            <li class="menubutton"><a href="../tutorial.html">Tutorials</a></li>
            <li class="menubutton"><a href="../install.html">Install</a></li>
            <li class="menubutton"><a href="../support.html">Support</a></li>
            <li class="menubutton"><a href="../apiref.html">API</a></li>
            <li class="menubutton"><a href="../about.html">About</a></li>
          </ul>
        </div>
      </div>
      

      <div class="clearer"></div>
    </div>

    
  <script type="text/javascript">
  var DOCUMENTATION_OPTIONS = {
    URL_ROOT: '../',
    VERSION: '2.3.0',
    COLLAPSE_INDEX: false,
    FILE_SUFFIX: '.html',
    HAS_SOURCE: true
  };
  </script>
    <script type="text/javascript" src="../_static/js/jquery-1.9.1.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery.qtip.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-migrate-1.1.1.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery.anythingslider.min.js"></script>

    
    <div class="document">
      
        <div id="thinbanner">
          <div id="bodythinbanner">
            <span class="h2gensim">models.phrases – Phrase (collocation) detection</span>
          </div>
        </div>
        <div class="obsah">
          <div class="obsahwrapper">
            
  <div class="section" id="module-gensim.models.phrases">
<span id="models-phrases-phrase-collocation-detection"></span><h1><code class="xref py py-mod docutils literal"><span class="pre">models.phrases</span></code> – Phrase (collocation) detection<a class="headerlink" href="#module-gensim.models.phrases" title="Permalink to this headline">¶</a></h1>
<p>Automatically detect common phrases (multiword expressions) from a stream of sentences.</p>
<p>The phrases are collocations (frequently co-occurring tokens). See <a class="footnote-reference" href="#id2" id="id1">[1]</a> for the
exact formula.</p>
<p>For example, if your input stream (=an iterable, with each value a list of token strings) looks like:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">sentence_stream</span><span class="p">))</span>
<span class="go">[[u&#39;the&#39;, u&#39;mayor&#39;, u&#39;of&#39;, u&#39;new&#39;, u&#39;york&#39;, u&#39;was&#39;, u&#39;there&#39;],</span>
<span class="go"> [u&#39;machine&#39;, u&#39;learning&#39;, u&#39;can&#39;, u&#39;be&#39;, u&#39;useful&#39;, u&#39;sometimes&#39;],</span>
<span class="go"> ...,</span>
<span class="go">]</span>
</pre></div>
</div>
<p>you’d train the detector with:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">phrases</span> <span class="o">=</span> <span class="n">Phrases</span><span class="p">(</span><span class="n">sentence_stream</span><span class="p">)</span>
</pre></div>
</div>
<p>and then create a performant Phraser object to transform any sentence (list of token strings) using the standard gensim syntax:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bigram</span> <span class="o">=</span> <span class="n">Phraser</span><span class="p">(</span><span class="n">phrases</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sent</span> <span class="o">=</span> <span class="p">[</span><span class="sa">u</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;mayor&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;new&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;york&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;was&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;there&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">bigram</span><span class="p">[</span><span class="n">sent</span><span class="p">])</span>
<span class="go">[u&#39;the&#39;, u&#39;mayor&#39;, u&#39;of&#39;, u&#39;new_york&#39;, u&#39;was&#39;, u&#39;there&#39;]</span>
</pre></div>
</div>
<p>(note <cite>new_york</cite> became a single token). As usual, you can also transform an entire
sentence stream using:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">bigram</span><span class="p">[</span><span class="n">any_sentence_stream</span><span class="p">]))</span>
<span class="go">[[u&#39;the&#39;, u&#39;mayor&#39;, u&#39;of&#39;, u&#39;new_york&#39;, u&#39;was&#39;, u&#39;there&#39;],</span>
<span class="go"> [u&#39;machine_learning&#39;, u&#39;can&#39;, u&#39;be&#39;, u&#39;useful&#39;, u&#39;sometimes&#39;],</span>
<span class="go"> ...,</span>
<span class="go">]</span>
</pre></div>
</div>
<p>You can also continue updating the collocation counts with new sentences, by:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bigram</span><span class="o">.</span><span class="n">add_vocab</span><span class="p">(</span><span class="n">new_sentence_stream</span><span class="p">)</span>
</pre></div>
</div>
<p>These <strong>phrase streams are meant to be used during text preprocessing, before
converting the resulting tokens into vectors using `Dictionary`</strong>. See the
<a class="reference internal" href="word2vec.html#module-gensim.models.word2vec" title="gensim.models.word2vec: Deep learning with word2vec"><code class="xref py py-mod docutils literal"><span class="pre">gensim.models.word2vec</span></code></a> module for an example application of using phrase detection.</p>
<p>The detection can also be <strong>run repeatedly</strong>, to get phrases longer than
two tokens (e.g. <cite>new_york_times</cite>):</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">trigram</span> <span class="o">=</span> <span class="n">Phrases</span><span class="p">(</span><span class="n">bigram</span><span class="p">[</span><span class="n">sentence_stream</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sent</span> <span class="o">=</span> <span class="p">[</span><span class="sa">u</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;new&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;york&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;times&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;newspaper&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">trigram</span><span class="p">[</span><span class="n">bigram</span><span class="p">[</span><span class="n">sent</span><span class="p">]])</span>
<span class="go">[u&#39;the&#39;, u&#39;new_york_times&#39;, u&#39;is&#39;, u&#39;a&#39;, u&#39;newspaper&#39;]</span>
</pre></div>
</div>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean.
Distributed Representations of Words and Phrases and their Compositionality.
In Proceedings of NIPS, 2013.</td></tr>
</tbody>
</table>
<dl class="class">
<dt id="gensim.models.phrases.Phraser">
<em class="property">class </em><code class="descclassname">gensim.models.phrases.</code><code class="descname">Phraser</code><span class="sig-paren">(</span><em>phrases_model</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phraser" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="../interfaces.html#gensim.interfaces.TransformationABC" title="gensim.interfaces.TransformationABC"><code class="xref py py-class docutils literal"><span class="pre">gensim.interfaces.TransformationABC</span></code></a></p>
<p>Minimal state &amp; functionality to apply results of a Phrases model to tokens.</p>
<p>After the one-time initialization, a Phraser will be much smaller and
somewhat faster than using the full Phrases model.</p>
<p>Reflects the results of the source model’s <cite>min_count</cite>, <cite>threshold</cite>, and
<cite>scoring</cite> settings. (You can tamper with those &amp; create a new Phraser to try
other values.)</p>
<dl class="method">
<dt id="gensim.models.phrases.Phraser.load">
<code class="descname">load</code><span class="sig-paren">(</span><em>fname</em>, <em>mmap=None</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phraser.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a previously saved object from file (also see <cite>save</cite>).</p>
<p>If the object was saved with large arrays stored separately, you can load
these arrays via mmap (shared memory) using <cite>mmap=’r’</cite>. Default: don’t use
mmap, load large arrays as normal objects.</p>
<p>If the file being loaded is compressed (either ‘.gz’ or ‘.bz2’), then
<cite>mmap=None</cite> must be set.  Load will raise an <cite>IOError</cite> if this condition
is encountered.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.phrases.Phraser.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>fname_or_handle</em>, <em>separately=None</em>, <em>sep_limit=10485760</em>, <em>ignore=frozenset([])</em>, <em>pickle_protocol=2</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phraser.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the object to file (also see <cite>load</cite>).</p>
<p><cite>fname_or_handle</cite> is either a string specifying the file name to
save to, or an open file-like object which can be written to. If
the object is a file handle, no special array handling will be
performed; all attributes will be saved to the same file.</p>
<p>If <cite>separately</cite> is None, automatically detect large
numpy/scipy.sparse arrays in the object being stored, and store
them into separate files. This avoids pickle memory errors and
allows mmap’ing large arrays back on load efficiently.</p>
<p>You can also set <cite>separately</cite> manually, in which case it must be
a list of attribute names to be stored in separate files. The
automatic check is not performed in this case.</p>
<p><cite>ignore</cite> is a set of attribute names to <em>not</em> serialize (file
handles, caches etc). On subsequent load() these attributes will
be set to None.</p>
<p><cite>pickle_protocol</cite> defaults to 2 so the pickled object can be imported
in both Python 2 and 3.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="gensim.models.phrases.Phrases">
<em class="property">class </em><code class="descclassname">gensim.models.phrases.</code><code class="descname">Phrases</code><span class="sig-paren">(</span><em>sentences=None</em>, <em>min_count=5</em>, <em>threshold=10.0</em>, <em>max_vocab_size=40000000</em>, <em>delimiter='_'</em>, <em>progress_per=10000</em>, <em>scoring='default'</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phrases" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="../interfaces.html#gensim.interfaces.TransformationABC" title="gensim.interfaces.TransformationABC"><code class="xref py py-class docutils literal"><span class="pre">gensim.interfaces.TransformationABC</span></code></a></p>
<p>Detect phrases, based on collected collocation counts. Adjacent words that appear
together more frequently than expected are joined together with the <cite>_</cite> character.</p>
<p>It can be used to generate phrases on the fly, using the <cite>phrases[sentence]</cite>
and <cite>phrases[corpus]</cite> syntax.</p>
<p>Initialize the model from an iterable of <cite>sentences</cite>. Each sentence must be
a list of words (unicode strings) that will be used for training.</p>
<p>The <cite>sentences</cite> iterable can be simply a list, but for larger corpora,
consider a generator that streams the sentences directly from disk/network,
without storing everything in RAM. See <code class="xref py py-class docutils literal"><span class="pre">BrownCorpus</span></code>,
<code class="xref py py-class docutils literal"><span class="pre">Text8Corpus</span></code> or <code class="xref py py-class docutils literal"><span class="pre">LineSentence</span></code> in the <a class="reference internal" href="word2vec.html#module-gensim.models.word2vec" title="gensim.models.word2vec: Deep learning with word2vec"><code class="xref py py-mod docutils literal"><span class="pre">gensim.models.word2vec</span></code></a>
module for such examples.</p>
<p><cite>min_count</cite> ignore all words and bigrams with total collected count lower
than this.</p>
<p><cite>threshold</cite> represents a score threshold for forming the phrases (higher means
fewer phrases). A phrase of words <cite>a</cite> followed by <cite>b</cite> is accepted if the score of the
phrase is greater than threshold. see the <a href="#id3"><span class="problematic" id="id4">`</span></a>scoring’ setting</p>
<p><cite>max_vocab_size</cite> is the maximum size of the vocabulary. Used to control
pruning of less common words, to keep memory under control. The default
of 40M needs about 3.6GB of RAM; increase/decrease <cite>max_vocab_size</cite> depending
on how much available memory you have.</p>
<p><cite>delimiter</cite> is the glue character used to join collocation tokens, and
should be a byte string (e.g. b’_’).</p>
<p><cite>scoring</cite> specifies how potential phrases are scored for comparison to the <cite>threshold</cite>
setting. two settings are available:
‘default’: from “Efficient Estimaton of Word Representations in Vector Space” by</p>
<blockquote>
<div>Mikolov, et. al.:
(count(worda followed by wordb) - min_count) * N /
(count(worda) * count(wordb)) &gt; threshold`, where <cite>N</cite> is the total vocabulary size.</div></blockquote>
<dl class="docutils">
<dt>‘npmi’: normalized pointwise mutual information, from “Normalized (Pointwise) Mutual</dt>
<dd>Information in Colocation Extraction” by Gerlof Bouma:
ln(prop(worda followed by wordb) / (prop(worda)*prop(wordb))) /
- ln(prop(worda followed by wordb)
where prop(n) is the count of n / the count of everything in the entire corpus</dd>
<dt>‘npmi’ is more robust when dealing with common words that form part of common bigrams, and</dt>
<dd>ranges from -1 to 1, but is slower to calculate than the default</dd>
</dl>
<dl class="method">
<dt id="gensim.models.phrases.Phrases.add_vocab">
<code class="descname">add_vocab</code><span class="sig-paren">(</span><em>sentences</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phrases.add_vocab" title="Permalink to this definition">¶</a></dt>
<dd><p>Merge the collected counts <cite>vocab</cite> into this phrase detector.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.phrases.Phrases.export_phrases">
<code class="descname">export_phrases</code><span class="sig-paren">(</span><em>sentences</em>, <em>out_delimiter=' '</em>, <em>as_tuples=False</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phrases.export_phrases" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate an iterator that contains all phrases in given ‘sentences’</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sentences</span> <span class="o">=</span> <span class="n">Text8Corpus</span><span class="p">(</span><span class="n">path_to_corpus</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bigram</span> <span class="o">=</span> <span class="n">Phrases</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">phrase</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">bigram</span><span class="o">.</span><span class="n">export_phrases</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">u</span><span class="s1">&#39;</span><span class="si">{0}</span><span class="s1">   </span><span class="si">{1}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">phrase</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>

<span class="go">  then you can debug the threshold with generated tsv</span>
</pre></div>
</div>
</dd></dl>

<dl class="staticmethod">
<dt id="gensim.models.phrases.Phrases.learn_vocab">
<em class="property">static </em><code class="descname">learn_vocab</code><span class="sig-paren">(</span><em>sentences</em>, <em>max_vocab_size</em>, <em>delimiter='_'</em>, <em>progress_per=10000</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phrases.learn_vocab" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect unigram/bigram counts from the <cite>sentences</cite> iterable.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.phrases.Phrases.load">
<code class="descname">load</code><span class="sig-paren">(</span><em>fname</em>, <em>mmap=None</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phrases.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a previously saved object from file (also see <cite>save</cite>).</p>
<p>If the object was saved with large arrays stored separately, you can load
these arrays via mmap (shared memory) using <cite>mmap=’r’</cite>. Default: don’t use
mmap, load large arrays as normal objects.</p>
<p>If the file being loaded is compressed (either ‘.gz’ or ‘.bz2’), then
<cite>mmap=None</cite> must be set.  Load will raise an <cite>IOError</cite> if this condition
is encountered.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="gensim.models.phrases.Phrases.npmi_scorer">
<em class="property">static </em><code class="descname">npmi_scorer</code><span class="sig-paren">(</span><em>worda_count</em>, <em>wordb_count</em>, <em>bigram_count</em>, <em>corpus_word_count=0.0</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phrases.npmi_scorer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="gensim.models.phrases.Phrases.original_scorer">
<em class="property">static </em><code class="descname">original_scorer</code><span class="sig-paren">(</span><em>worda_count</em>, <em>wordb_count</em>, <em>bigram_count</em>, <em>len_vocab=0.0</em>, <em>min_count=0.0</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phrases.original_scorer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="gensim.models.phrases.Phrases.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>fname_or_handle</em>, <em>separately=None</em>, <em>sep_limit=10485760</em>, <em>ignore=frozenset([])</em>, <em>pickle_protocol=2</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phrases.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the object to file (also see <cite>load</cite>).</p>
<p><cite>fname_or_handle</cite> is either a string specifying the file name to
save to, or an open file-like object which can be written to. If
the object is a file handle, no special array handling will be
performed; all attributes will be saved to the same file.</p>
<p>If <cite>separately</cite> is None, automatically detect large
numpy/scipy.sparse arrays in the object being stored, and store
them into separate files. This avoids pickle memory errors and
allows mmap’ing large arrays back on load efficiently.</p>
<p>You can also set <cite>separately</cite> manually, in which case it must be
a list of attribute names to be stored in separate files. The
automatic check is not performed in this case.</p>
<p><cite>ignore</cite> is a set of attribute names to <em>not</em> serialize (file
handles, caches etc). On subsequent load() these attributes will
be set to None.</p>
<p><cite>pickle_protocol</cite> defaults to 2 so the pickled object can be imported
in both Python 2 and 3.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="gensim.models.phrases.pseudocorpus">
<code class="descclassname">gensim.models.phrases.</code><code class="descname">pseudocorpus</code><span class="sig-paren">(</span><em>source_vocab</em>, <em>sep</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.pseudocorpus" title="Permalink to this definition">¶</a></dt>
<dd><p>Feeds source_vocab’s compound keys back to it, to discover phrases</p>
</dd></dl>

</div>


          </div>
        </div>
      

      <div class="clearer"></div>
    </div>
    

    
    <div id="footer">
      <div id="footerwrapper">
        <div id="footerleft">
          <img src="../_static/images/logo-gensim.png" class="smallerlogo" alt="smaller gensim logo" />
          <a href="../index.html"><img src="../_static/images/gensim-footer.png" alt="gensim footer image" title="Gensim home" /></a>

          <div class="copyright">
            &copy; Copyright 2009-now, <a href="mailto:radimrehurek@seznam.cz" style="color:white"> Radim Řehůřek</a>
            <br />
              Last updated on Sep 10, 2017.
          </div>
        </div>

        <div id="footermiddleright">
          <div id="footermiddle">
            <ul class="navigation">
              <li><a href="../index.html">
                Home
              </a></li>
              <li>|</li>
              <li><a href="../tutorial.html">
                Tutorials
              </a></li>
              <li>|</li>
              <li><a href="../install.html">
                Install
              </a></li>
              <li>|</li>
              <li><a href="../support.html">
                Support
              </a></li>
              <li>|</li>
              <li><a href="../apiref.html">
                API
              </a></li>
              <li>|</li>
              <li><a href="../about.html">
                About
              </a></li>
            </ul>

            <div class="tweetodsazeni">
              <div class="tweet">
                <a href="https://twitter.com/radimrehurek" target="_blank" style="color: white">Tweet @RadimRehurek</a>
              </div>
            </div>

          </div>

          <div id="footerright">
            <div class="footernadpis">
              Support:
            </div>
            <div class="googlegroupsodsazeni">
              <a href="https://groups.google.com/group/gensim" class="googlegroups">
                Stay informed via gensim mailing list:
              </a>

              <form action="http://groups.google.com/group/gensim/boxsubscribe">
                <input type="text" name="email" placeholder="your@email.com" size="28" />
                <input type="submit" name="sub" value="Subscribe" />
              </form>

            </div>

            <div class="addthis_toolbox addthis_default_style addthis_32x32_style"
                addthis:title="#gensim"
                addthis:description="Efficient Topic Modelling in Python"
                style="margin:20px 0 0 0">
              <a class="addthis_button_preferred_1"></a>
              <a class="addthis_button_preferred_2"></a>
              <a class="addthis_button_preferred_3"></a>
              <a class="addthis_button_preferred_4"></a>
              <a class="addthis_button_compact"></a>
              <a class="addthis_counter addthis_bubble_style"></a>
            </div>
          </div>

        </div>
      </div>
    </div>
    

    <script type="text/javascript">
      (function() {
      var at = document.createElement('script'); at.type = 'text/javascript'; at.async = true;
      at.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 's7.addthis.com/js/250/addthis_widget.js#pubid=ra-4d738b9b1d31ccbd';
      var sat = document.getElementsByTagName('script')[0]; sat.parentNode.insertBefore(at, sat);
      })();
    </script>

  </body>
</html>