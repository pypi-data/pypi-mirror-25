{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Decode BBCI Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to read and decode BBCI data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup logging to see outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.DEBUG, stream=sys.stdout)\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set the filename and the sensors you want to load. If you set\n",
    "\n",
    "```python\n",
    "load_sensor_names=None\n",
    "```\n",
    "\n",
    "or just remove the parameter from the function call, all sensors will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=3, n_times=3451320\n",
      "    Range : 0 ... 3451319 =      0.000 ...  6902.638 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datasets.bbci import BBCIDataset\n",
    "train_filename = '/home/schirrmr/data/BBCI-without-last-runs/BhNoMoSc1S001R01_ds10_1-12.BBCI.mat'\n",
    "cnt = BBCIDataset(train_filename, load_sensor_names=['C3', 'CPz', 'C4']).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing on continous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First remove the stimulus channel, than apply any preprocessing you like. There are some very few directions available from Braindecode, such as resample_cnt. But you can apply any function on the chan x time matrix of the mne raw object (`cnt` in the code) by calling `mne_apply` with two arguments:\n",
    "\n",
    "1. Your function (2d-array-> 2darray), that transforms the channel x timesteps data array\n",
    "2. the Raw data object from mne itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-04 17:15:10,854 WARNING : This is not causal, uses future data....\n",
      "2017-09-04 17:15:10,855 INFO : Resampling from 500.000000 to 250.000000 Hz.\n",
      "Creating RawArray with float64 data, n_channels=3, n_times=1725660\n",
      "    Range : 0 ... 1725659 =      0.000 ...  6902.636 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "from braindecode.mne_ext.signalproc import resample_cnt, mne_apply\n",
    "from braindecode.datautil.signalproc import exponential_running_standardize\n",
    "# Remove stimulus channel\n",
    "cnt = cnt.drop_channels(['STI 014'])\n",
    "cnt = resample_cnt(cnt, 250)\n",
    "# mne apply will apply the function to the data (a 2d-numpy-array)\n",
    "# have to transpose data back and forth, since\n",
    "# exponential_running_standardize expects time x chans order\n",
    "# while mne object has chans x time order\n",
    "cnt = mne_apply(lambda a: exponential_running_standardize(\n",
    "    a.T, init_block_size=1000,factor_new=0.001, eps=1e-4).T,\n",
    "    cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to epoched dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Braindecode supplies the `create_signal_target_from_raw_mne` function, which will transform the mne raw object into a `SignalAndTarget` object for use in Braindecode.\n",
    "`name_to_code` should be an `OrderedDict` that maps class names to either one or a list of marker codes for that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-04 17:15:12,903 INFO : Trial per class:\n",
      "Counter({'Feet': 225, 'Right': 224, 'Rest': 224, 'Left': 224})\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne\n",
    "from collections import OrderedDict\n",
    "# can also give lists of marker codes in case a class has multiple marker codes...\n",
    "name_to_code = OrderedDict([('Right', 1), ('Left', 2), ('Rest', 3), ('Feet', 4)])\n",
    "segment_ival_ms = [-500,4000]\n",
    "\n",
    "train_set = create_signal_target_from_raw_mne(cnt, name_to_code, segment_ival_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=3, n_times=617090\n",
      "    Range : 0 ... 617089 =      0.000 ...  1234.178 secs\n",
      "Ready.\n",
      "2017-09-04 17:15:13,545 WARNING : This is not causal, uses future data....\n",
      "2017-09-04 17:15:13,546 INFO : Resampling from 500.000000 to 250.000000 Hz.\n",
      "Creating RawArray with float64 data, n_channels=3, n_times=308545\n",
      "    Range : 0 ... 308544 =      0.000 ...  1234.176 secs\n",
      "Ready.\n",
      "2017-09-04 17:15:13,881 INFO : Trial per class:\n",
      "Counter({'Feet': 40, 'Left': 40, 'Rest': 40, 'Right': 40})\n"
     ]
    }
   ],
   "source": [
    "test_filename = '/home/schirrmr/data/BBCI-only-last-runs/BhNoMoSc1S001R13_ds10_1-2BBCI.mat'\n",
    "cnt = BBCIDataset(test_filename, load_sensor_names=['C3', 'CPz', 'C4']).load()\n",
    "# Remove stimulus channel\n",
    "cnt = cnt.drop_channels(['STI 014'])\n",
    "cnt = resample_cnt(cnt, 250)\n",
    "cnt = mne_apply(lambda a: exponential_running_standardize(\n",
    "    a.T, init_block_size=1000,factor_new=0.001, eps=1e-4).T,\n",
    "    cnt)\n",
    "test_set = create_signal_target_from_raw_mne(cnt, name_to_code, segment_ival_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "In case of start and stop markers, provide a `name_to_stop_codes` dictionary (same as for the start codes in this example) as a final argument to `create_signal_target_from_raw_mne`. See [Read and Decode BBCI Data with Start-Stop-Markers Tutorial](BBCI_Data_Start_Stop.html)\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split off a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.splitters import split_into_two_sets\n",
    "\n",
    "train_set, valid_set = split_into_two_sets(train_set, first_set_fraction=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "from braindecode.models.util import to_dense_prediction_model\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = True\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = 800\n",
    "in_chans = 3\n",
    "n_classes = 4\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length=30).create_network()\n",
    "to_dense_prediction_model(model)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup optimizer and iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267 predictions per input/trial\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "from braindecode.torch_ext.util import np_to_var\n",
    "# determine output size\n",
    "test_input = np_to_var(np.ones((2, 3, input_time_length, 1), dtype=np.float32))\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "print(\"{:d} predictions per input/trial\".format(n_preds_per_input))\n",
    "\n",
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "iterator = CropsFromTrialsIterator(batch_size=32,input_time_length=input_time_length,\n",
    "                                  n_preds_per_input=n_preds_per_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Monitors, Loss function, Stop Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.experiments.experiment import Experiment\n",
    "from braindecode.experiments.monitors import RuntimeMonitor, LossMonitor, CroppedTrialMisclassMonitor, MisclassMonitor\n",
    "from braindecode.experiments.stopcriteria import MaxEpochs\n",
    "import torch.nn.functional as F\n",
    "import torch as th\n",
    "from braindecode.torch_ext.modules import Expression\n",
    "\n",
    "\n",
    "loss_function = lambda preds, targets: F.nll_loss(th.mean(preds, dim=2).squeeze(), targets)\n",
    "\n",
    "model_constraint = None\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='sample_misclass'),\n",
    "            CroppedTrialMisclassMonitor(input_time_length), RuntimeMonitor(),]\n",
    "stop_criterion = MaxEpochs(20)\n",
    "exp = Experiment(model, train_set, valid_set, test_set, iterator, loss_function, optimizer, model_constraint,\n",
    "          monitors, stop_criterion, remember_best_column='valid_misclass',\n",
    "          run_after_early_stop=True, batch_modifier=None, cuda=cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-04 17:15:20,602 INFO : Run until first stop...\n",
      "2017-09-04 17:15:21,327 INFO : Epoch 0\n",
      "2017-09-04 17:15:21,329 INFO : train_loss                7.89184\n",
      "2017-09-04 17:15:21,330 INFO : valid_loss                7.72731\n",
      "2017-09-04 17:15:21,331 INFO : test_loss                 7.75617\n",
      "2017-09-04 17:15:21,331 INFO : train_sample_misclass     0.75013\n",
      "2017-09-04 17:15:21,332 INFO : valid_sample_misclass     0.74856\n",
      "2017-09-04 17:15:21,333 INFO : test_sample_misclass      0.75115\n",
      "2017-09-04 17:15:21,334 INFO : train_misclass            0.75070\n",
      "2017-09-04 17:15:21,334 INFO : valid_misclass            0.74860\n",
      "2017-09-04 17:15:21,335 INFO : test_misclass             0.75000\n",
      "2017-09-04 17:15:21,336 INFO : runtime                   0.00000\n",
      "2017-09-04 17:15:21,337 INFO : \n",
      "2017-09-04 17:15:21,338 INFO : New best valid_misclass: 0.748603\n",
      "2017-09-04 17:15:21,339 INFO : \n",
      "2017-09-04 17:15:22,128 INFO : Time only for training updates: 0.55s\n",
      "2017-09-04 17:15:22,813 INFO : Epoch 1\n",
      "2017-09-04 17:15:22,815 INFO : train_loss                0.79609\n",
      "2017-09-04 17:15:22,815 INFO : valid_loss                0.79313\n",
      "2017-09-04 17:15:22,816 INFO : test_loss                 0.83698\n",
      "2017-09-04 17:15:22,817 INFO : train_sample_misclass     0.36967\n",
      "2017-09-04 17:15:22,818 INFO : valid_sample_misclass     0.37417\n",
      "2017-09-04 17:15:22,818 INFO : test_sample_misclass      0.43014\n",
      "2017-09-04 17:15:22,819 INFO : train_misclass            0.30084\n",
      "2017-09-04 17:15:22,820 INFO : valid_misclass            0.26257\n",
      "2017-09-04 17:15:22,821 INFO : test_misclass             0.34375\n",
      "2017-09-04 17:15:22,821 INFO : runtime                   1.52622\n",
      "2017-09-04 17:15:22,822 INFO : \n",
      "2017-09-04 17:15:22,824 INFO : New best valid_misclass: 0.262570\n",
      "2017-09-04 17:15:22,825 INFO : \n",
      "2017-09-04 17:15:23,598 INFO : Time only for training updates: 0.54s\n",
      "2017-09-04 17:15:24,280 INFO : Epoch 2\n",
      "2017-09-04 17:15:24,281 INFO : train_loss                0.68135\n",
      "2017-09-04 17:15:24,282 INFO : valid_loss                0.65885\n",
      "2017-09-04 17:15:24,282 INFO : test_loss                 0.74209\n",
      "2017-09-04 17:15:24,283 INFO : train_sample_misclass     0.29296\n",
      "2017-09-04 17:15:24,284 INFO : valid_sample_misclass     0.30234\n",
      "2017-09-04 17:15:24,285 INFO : test_sample_misclass      0.37382\n",
      "2017-09-04 17:15:24,285 INFO : train_misclass            0.22423\n",
      "2017-09-04 17:15:24,286 INFO : valid_misclass            0.21229\n",
      "2017-09-04 17:15:24,287 INFO : test_misclass             0.30000\n",
      "2017-09-04 17:15:24,288 INFO : runtime                   1.46980\n",
      "2017-09-04 17:15:24,288 INFO : \n",
      "2017-09-04 17:15:24,290 INFO : New best valid_misclass: 0.212291\n",
      "2017-09-04 17:15:24,291 INFO : \n",
      "2017-09-04 17:15:25,074 INFO : Time only for training updates: 0.55s\n",
      "2017-09-04 17:15:25,755 INFO : Epoch 3\n",
      "2017-09-04 17:15:25,756 INFO : train_loss                0.65340\n",
      "2017-09-04 17:15:25,757 INFO : valid_loss                0.68531\n",
      "2017-09-04 17:15:25,758 INFO : test_loss                 0.81644\n",
      "2017-09-04 17:15:25,759 INFO : train_sample_misclass     0.27799\n",
      "2017-09-04 17:15:25,759 INFO : valid_sample_misclass     0.32095\n",
      "2017-09-04 17:15:25,760 INFO : test_sample_misclass      0.43623\n",
      "2017-09-04 17:15:25,761 INFO : train_misclass            0.20195\n",
      "2017-09-04 17:15:25,762 INFO : valid_misclass            0.25140\n",
      "2017-09-04 17:15:25,762 INFO : test_misclass             0.35000\n",
      "2017-09-04 17:15:25,763 INFO : runtime                   1.47547\n",
      "2017-09-04 17:15:25,764 INFO : \n",
      "2017-09-04 17:15:26,546 INFO : Time only for training updates: 0.55s\n",
      "2017-09-04 17:15:27,235 INFO : Epoch 4\n",
      "2017-09-04 17:15:27,237 INFO : train_loss                0.59239\n",
      "2017-09-04 17:15:27,238 INFO : valid_loss                0.60564\n",
      "2017-09-04 17:15:27,239 INFO : test_loss                 0.74526\n",
      "2017-09-04 17:15:27,239 INFO : train_sample_misclass     0.26274\n",
      "2017-09-04 17:15:27,240 INFO : valid_sample_misclass     0.27282\n",
      "2017-09-04 17:15:27,241 INFO : test_sample_misclass      0.36302\n",
      "2017-09-04 17:15:27,242 INFO : train_misclass            0.20195\n",
      "2017-09-04 17:15:27,242 INFO : valid_misclass            0.20670\n",
      "2017-09-04 17:15:27,243 INFO : test_misclass             0.31250\n",
      "2017-09-04 17:15:27,244 INFO : runtime                   1.47257\n",
      "2017-09-04 17:15:27,244 INFO : \n",
      "2017-09-04 17:15:27,247 INFO : New best valid_misclass: 0.206704\n",
      "2017-09-04 17:15:27,247 INFO : \n",
      "2017-09-04 17:15:28,024 INFO : Time only for training updates: 0.54s\n",
      "2017-09-04 17:15:28,704 INFO : Epoch 5\n",
      "2017-09-04 17:15:28,705 INFO : train_loss                0.83419\n",
      "2017-09-04 17:15:28,706 INFO : valid_loss                0.71909\n",
      "2017-09-04 17:15:28,707 INFO : test_loss                 0.78308\n",
      "2017-09-04 17:15:28,708 INFO : train_sample_misclass     0.31476\n",
      "2017-09-04 17:15:28,708 INFO : valid_sample_misclass     0.33006\n",
      "2017-09-04 17:15:28,709 INFO : test_sample_misclass      0.36006\n",
      "2017-09-04 17:15:28,710 INFO : train_misclass            0.26741\n",
      "2017-09-04 17:15:28,711 INFO : valid_misclass            0.26816\n",
      "2017-09-04 17:15:28,711 INFO : test_misclass             0.28750\n",
      "2017-09-04 17:15:28,712 INFO : runtime                   1.47763\n",
      "2017-09-04 17:15:28,713 INFO : \n",
      "2017-09-04 17:15:29,490 INFO : Time only for training updates: 0.54s\n",
      "2017-09-04 17:15:30,171 INFO : Epoch 6\n",
      "2017-09-04 17:15:30,172 INFO : train_loss                0.65843\n",
      "2017-09-04 17:15:30,173 INFO : valid_loss                0.70323\n",
      "2017-09-04 17:15:30,174 INFO : test_loss                 0.78840\n",
      "2017-09-04 17:15:30,174 INFO : train_sample_misclass     0.29380\n",
      "2017-09-04 17:15:30,175 INFO : valid_sample_misclass     0.31052\n",
      "2017-09-04 17:15:30,176 INFO : test_sample_misclass      0.38173\n",
      "2017-09-04 17:15:30,177 INFO : train_misclass            0.24652\n",
      "2017-09-04 17:15:30,177 INFO : valid_misclass            0.22905\n",
      "2017-09-04 17:15:30,178 INFO : test_misclass             0.34375\n",
      "2017-09-04 17:15:30,179 INFO : runtime                   1.46631\n",
      "2017-09-04 17:15:30,180 INFO : \n",
      "2017-09-04 17:15:30,957 INFO : Time only for training updates: 0.54s\n",
      "2017-09-04 17:15:31,637 INFO : Epoch 7\n",
      "2017-09-04 17:15:31,638 INFO : train_loss                0.59129\n",
      "2017-09-04 17:15:31,639 INFO : valid_loss                0.57418\n",
      "2017-09-04 17:15:31,640 INFO : test_loss                 0.68466\n",
      "2017-09-04 17:15:31,641 INFO : train_sample_misclass     0.24313\n",
      "2017-09-04 17:15:31,642 INFO : valid_sample_misclass     0.26601\n",
      "2017-09-04 17:15:31,642 INFO : test_sample_misclass      0.33695\n",
      "2017-09-04 17:15:31,643 INFO : train_misclass            0.16852\n",
      "2017-09-04 17:15:31,644 INFO : valid_misclass            0.16201\n",
      "2017-09-04 17:15:31,644 INFO : test_misclass             0.28750\n",
      "2017-09-04 17:15:31,645 INFO : runtime                   1.46682\n",
      "2017-09-04 17:15:31,646 INFO : \n",
      "2017-09-04 17:15:31,648 INFO : New best valid_misclass: 0.162011\n",
      "2017-09-04 17:15:31,649 INFO : \n",
      "2017-09-04 17:15:32,432 INFO : Time only for training updates: 0.55s\n",
      "2017-09-04 17:15:33,115 INFO : Epoch 8\n",
      "2017-09-04 17:15:33,116 INFO : train_loss                0.51898\n",
      "2017-09-04 17:15:33,117 INFO : valid_loss                0.56007\n",
      "2017-09-04 17:15:33,118 INFO : test_loss                 0.68855\n",
      "2017-09-04 17:15:33,118 INFO : train_sample_misclass     0.22688\n",
      "2017-09-04 17:15:33,119 INFO : valid_sample_misclass     0.25343\n",
      "2017-09-04 17:15:33,120 INFO : test_sample_misclass      0.33530\n",
      "2017-09-04 17:15:33,120 INFO : train_misclass            0.16852\n",
      "2017-09-04 17:15:33,121 INFO : valid_misclass            0.16760\n",
      "2017-09-04 17:15:33,122 INFO : test_misclass             0.23750\n",
      "2017-09-04 17:15:33,123 INFO : runtime                   1.47464\n",
      "2017-09-04 17:15:33,123 INFO : \n",
      "2017-09-04 17:15:33,905 INFO : Time only for training updates: 0.55s\n",
      "2017-09-04 17:15:34,586 INFO : Epoch 9\n",
      "2017-09-04 17:15:34,588 INFO : train_loss                0.48737\n",
      "2017-09-04 17:15:34,588 INFO : valid_loss                0.55193\n",
      "2017-09-04 17:15:34,589 INFO : test_loss                 0.66112\n",
      "2017-09-04 17:15:34,590 INFO : train_sample_misclass     0.19905\n",
      "2017-09-04 17:15:34,591 INFO : valid_sample_misclass     0.24962\n",
      "2017-09-04 17:15:34,591 INFO : test_sample_misclass      0.31659\n",
      "2017-09-04 17:15:34,592 INFO : train_misclass            0.12256\n",
      "2017-09-04 17:15:34,593 INFO : valid_misclass            0.15642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-04 17:15:34,594 INFO : test_misclass             0.21875\n",
      "2017-09-04 17:15:34,595 INFO : runtime                   1.47319\n",
      "2017-09-04 17:15:34,595 INFO : \n",
      "2017-09-04 17:15:34,597 INFO : New best valid_misclass: 0.156425\n",
      "2017-09-04 17:15:34,598 INFO : \n",
      "2017-09-04 17:15:35,381 INFO : Time only for training updates: 0.55s\n",
      "2017-09-04 17:15:36,061 INFO : Epoch 10\n",
      "2017-09-04 17:15:36,063 INFO : train_loss                0.49131\n",
      "2017-09-04 17:15:36,063 INFO : valid_loss                0.49629\n",
      "2017-09-04 17:15:36,064 INFO : test_loss                 0.59242\n",
      "2017-09-04 17:15:36,065 INFO : train_sample_misclass     0.19331\n",
      "2017-09-04 17:15:36,066 INFO : valid_sample_misclass     0.22607\n",
      "2017-09-04 17:15:36,066 INFO : test_sample_misclass      0.26958\n",
      "2017-09-04 17:15:36,067 INFO : train_misclass            0.12396\n",
      "2017-09-04 17:15:36,068 INFO : valid_misclass            0.16201\n",
      "2017-09-04 17:15:36,069 INFO : test_misclass             0.18750\n",
      "2017-09-04 17:15:36,069 INFO : runtime                   1.47590\n",
      "2017-09-04 17:15:36,070 INFO : \n",
      "2017-09-04 17:15:36,853 INFO : Time only for training updates: 0.55s\n",
      "2017-09-04 17:15:37,534 INFO : Epoch 11\n",
      "2017-09-04 17:15:37,536 INFO : train_loss                0.48746\n",
      "2017-09-04 17:15:37,536 INFO : valid_loss                0.53799\n",
      "2017-09-04 17:15:37,537 INFO : test_loss                 0.62392\n",
      "2017-09-04 17:15:37,538 INFO : train_sample_misclass     0.19512\n",
      "2017-09-04 17:15:37,539 INFO : valid_sample_misclass     0.24528\n",
      "2017-09-04 17:15:37,539 INFO : test_sample_misclass      0.30784\n",
      "2017-09-04 17:15:37,540 INFO : train_misclass            0.12256\n",
      "2017-09-04 17:15:37,541 INFO : valid_misclass            0.16201\n",
      "2017-09-04 17:15:37,542 INFO : test_misclass             0.18750\n",
      "2017-09-04 17:15:37,542 INFO : runtime                   1.47192\n",
      "2017-09-04 17:15:37,543 INFO : \n",
      "2017-09-04 17:15:38,325 INFO : Time only for training updates: 0.55s\n",
      "2017-09-04 17:15:39,005 INFO : Epoch 12\n",
      "2017-09-04 17:15:39,006 INFO : train_loss                0.48983\n",
      "2017-09-04 17:15:39,007 INFO : valid_loss                0.53578\n",
      "2017-09-04 17:15:39,008 INFO : test_loss                 0.63775\n",
      "2017-09-04 17:15:39,009 INFO : train_sample_misclass     0.20677\n",
      "2017-09-04 17:15:39,009 INFO : valid_sample_misclass     0.23664\n",
      "2017-09-04 17:15:39,010 INFO : test_sample_misclass      0.31259\n",
      "2017-09-04 17:15:39,011 INFO : train_misclass            0.13370\n",
      "2017-09-04 17:15:39,012 INFO : valid_misclass            0.18994\n",
      "2017-09-04 17:15:39,012 INFO : test_misclass             0.23125\n",
      "2017-09-04 17:15:39,013 INFO : runtime                   1.47232\n",
      "2017-09-04 17:15:39,014 INFO : \n",
      "2017-09-04 17:15:39,795 INFO : Time only for training updates: 0.55s\n",
      "2017-09-04 17:15:40,478 INFO : Epoch 13\n",
      "2017-09-04 17:15:40,479 INFO : train_loss                0.52784\n",
      "2017-09-04 17:15:40,480 INFO : valid_loss                0.56692\n",
      "2017-09-04 17:15:40,481 INFO : test_loss                 0.75610\n",
      "2017-09-04 17:15:40,482 INFO : train_sample_misclass     0.21850\n",
      "2017-09-04 17:15:40,483 INFO : valid_sample_misclass     0.25799\n",
      "2017-09-04 17:15:40,483 INFO : test_sample_misclass      0.36978\n",
      "2017-09-04 17:15:40,484 INFO : train_misclass            0.15738\n",
      "2017-09-04 17:15:40,485 INFO : valid_misclass            0.16201\n",
      "2017-09-04 17:15:40,486 INFO : test_misclass             0.26875\n",
      "2017-09-04 17:15:40,486 INFO : runtime                   1.46998\n",
      "2017-09-04 17:15:40,487 INFO : \n",
      "2017-09-04 17:15:41,270 INFO : Time only for training updates: 0.55s\n",
      "2017-09-04 17:15:41,959 INFO : Epoch 14\n",
      "2017-09-04 17:15:41,960 INFO : train_loss                0.47720\n",
      "2017-09-04 17:15:41,961 INFO : valid_loss                0.49591\n",
      "2017-09-04 17:15:41,962 INFO : test_loss                 0.61555\n",
      "2017-09-04 17:15:41,963 INFO : train_sample_misclass     0.18955\n",
      "2017-09-04 17:15:41,964 INFO : valid_sample_misclass     0.21733\n",
      "2017-09-04 17:15:41,964 INFO : test_sample_misclass      0.30016\n",
      "2017-09-04 17:15:41,965 INFO : train_misclass            0.10864\n",
      "2017-09-04 17:15:41,966 INFO : valid_misclass            0.15084\n",
      "2017-09-04 17:15:41,967 INFO : test_misclass             0.23125\n",
      "2017-09-04 17:15:41,967 INFO : runtime                   1.47534\n",
      "2017-09-04 17:15:41,968 INFO : \n",
      "2017-09-04 17:15:41,970 INFO : New best valid_misclass: 0.150838\n",
      "2017-09-04 17:15:41,971 INFO : \n",
      "2017-09-04 17:15:42,748 INFO : Time only for training updates: 0.54s\n",
      "2017-09-04 17:15:43,432 INFO : Epoch 15\n",
      "2017-09-04 17:15:43,433 INFO : train_loss                0.56211\n",
      "2017-09-04 17:15:43,434 INFO : valid_loss                0.52681\n",
      "2017-09-04 17:15:43,435 INFO : test_loss                 0.61909\n",
      "2017-09-04 17:15:43,435 INFO : train_sample_misclass     0.20645\n",
      "2017-09-04 17:15:43,436 INFO : valid_sample_misclass     0.23300\n",
      "2017-09-04 17:15:43,437 INFO : test_sample_misclass      0.30687\n",
      "2017-09-04 17:15:43,437 INFO : train_misclass            0.13370\n",
      "2017-09-04 17:15:43,438 INFO : valid_misclass            0.16201\n",
      "2017-09-04 17:15:43,439 INFO : test_misclass             0.24375\n",
      "2017-09-04 17:15:43,440 INFO : runtime                   1.47778\n",
      "2017-09-04 17:15:43,440 INFO : \n",
      "2017-09-04 17:15:44,219 INFO : Time only for training updates: 0.54s\n",
      "2017-09-04 17:15:44,900 INFO : Epoch 16\n",
      "2017-09-04 17:15:44,901 INFO : train_loss                0.49793\n",
      "2017-09-04 17:15:44,902 INFO : valid_loss                0.52896\n",
      "2017-09-04 17:15:44,902 INFO : test_loss                 0.63775\n",
      "2017-09-04 17:15:44,903 INFO : train_sample_misclass     0.20522\n",
      "2017-09-04 17:15:44,904 INFO : valid_sample_misclass     0.21733\n",
      "2017-09-04 17:15:44,905 INFO : test_sample_misclass      0.31226\n",
      "2017-09-04 17:15:44,905 INFO : train_misclass            0.16295\n",
      "2017-09-04 17:15:44,906 INFO : valid_misclass            0.17877\n",
      "2017-09-04 17:15:44,907 INFO : test_misclass             0.24375\n",
      "2017-09-04 17:15:44,908 INFO : runtime                   1.47052\n",
      "2017-09-04 17:15:44,908 INFO : \n",
      "2017-09-04 17:15:45,687 INFO : Time only for training updates: 0.54s\n",
      "2017-09-04 17:15:46,367 INFO : Epoch 17\n",
      "2017-09-04 17:15:46,369 INFO : train_loss                0.52470\n",
      "2017-09-04 17:15:46,370 INFO : valid_loss                0.59936\n",
      "2017-09-04 17:15:46,370 INFO : test_loss                 0.70618\n",
      "2017-09-04 17:15:46,371 INFO : train_sample_misclass     0.22246\n",
      "2017-09-04 17:15:46,372 INFO : valid_sample_misclass     0.25435\n",
      "2017-09-04 17:15:46,373 INFO : test_sample_misclass      0.33122\n",
      "2017-09-04 17:15:46,373 INFO : train_misclass            0.16992\n",
      "2017-09-04 17:15:46,374 INFO : valid_misclass            0.18994\n",
      "2017-09-04 17:15:46,375 INFO : test_misclass             0.23750\n",
      "2017-09-04 17:15:46,376 INFO : runtime                   1.46793\n",
      "2017-09-04 17:15:46,376 INFO : \n",
      "2017-09-04 17:15:47,154 INFO : Time only for training updates: 0.54s\n",
      "2017-09-04 17:15:47,835 INFO : Epoch 18\n",
      "2017-09-04 17:15:47,836 INFO : train_loss                0.48388\n",
      "2017-09-04 17:15:47,837 INFO : valid_loss                0.55803\n",
      "2017-09-04 17:15:47,838 INFO : test_loss                 0.64165\n",
      "2017-09-04 17:15:47,839 INFO : train_sample_misclass     0.20329\n",
      "2017-09-04 17:15:47,839 INFO : valid_sample_misclass     0.26238\n",
      "2017-09-04 17:15:47,840 INFO : test_sample_misclass      0.31140\n",
      "2017-09-04 17:15:47,841 INFO : train_misclass            0.12674\n",
      "2017-09-04 17:15:47,842 INFO : valid_misclass            0.17318\n",
      "2017-09-04 17:15:47,842 INFO : test_misclass             0.21250\n",
      "2017-09-04 17:15:47,843 INFO : runtime                   1.46780\n",
      "2017-09-04 17:15:47,844 INFO : \n",
      "2017-09-04 17:15:48,622 INFO : Time only for training updates: 0.54s\n",
      "2017-09-04 17:15:49,305 INFO : Epoch 19\n",
      "2017-09-04 17:15:49,306 INFO : train_loss                0.49836\n",
      "2017-09-04 17:15:49,307 INFO : valid_loss                0.54167\n",
      "2017-09-04 17:15:49,308 INFO : test_loss                 0.67707\n",
      "2017-09-04 17:15:49,309 INFO : train_sample_misclass     0.20662\n",
      "2017-09-04 17:15:49,309 INFO : valid_sample_misclass     0.24228\n",
      "2017-09-04 17:15:49,310 INFO : test_sample_misclass      0.33356\n",
      "2017-09-04 17:15:49,311 INFO : train_misclass            0.13928\n",
      "2017-09-04 17:15:49,312 INFO : valid_misclass            0.14525\n",
      "2017-09-04 17:15:49,312 INFO : test_misclass             0.22500\n",
      "2017-09-04 17:15:49,313 INFO : runtime                   1.46808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-04 17:15:49,314 INFO : \n",
      "2017-09-04 17:15:49,316 INFO : New best valid_misclass: 0.145251\n",
      "2017-09-04 17:15:49,317 INFO : \n",
      "2017-09-04 17:15:50,099 INFO : Time only for training updates: 0.55s\n",
      "2017-09-04 17:15:50,779 INFO : Epoch 20\n",
      "2017-09-04 17:15:50,780 INFO : train_loss                0.46336\n",
      "2017-09-04 17:15:50,781 INFO : valid_loss                0.52239\n",
      "2017-09-04 17:15:50,781 INFO : test_loss                 0.58432\n",
      "2017-09-04 17:15:50,782 INFO : train_sample_misclass     0.17653\n",
      "2017-09-04 17:15:50,783 INFO : valid_sample_misclass     0.22818\n",
      "2017-09-04 17:15:50,784 INFO : test_sample_misclass      0.27456\n",
      "2017-09-04 17:15:50,784 INFO : train_misclass            0.10028\n",
      "2017-09-04 17:15:50,785 INFO : valid_misclass            0.15084\n",
      "2017-09-04 17:15:50,786 INFO : test_misclass             0.19375\n",
      "2017-09-04 17:15:50,787 INFO : runtime                   1.47624\n",
      "2017-09-04 17:15:50,787 INFO : \n",
      "2017-09-04 17:15:50,788 INFO : Setup for second stop...\n",
      "2017-09-04 17:15:50,791 INFO : Train loss to reach 0.49836\n",
      "2017-09-04 17:15:50,792 INFO : Run until second stop...\n",
      "2017-09-04 17:15:51,603 INFO : Epoch 20\n",
      "2017-09-04 17:15:51,604 INFO : train_loss                0.50700\n",
      "2017-09-04 17:15:51,604 INFO : valid_loss                0.54167\n",
      "2017-09-04 17:15:51,605 INFO : test_loss                 0.67707\n",
      "2017-09-04 17:15:51,606 INFO : train_sample_misclass     0.21374\n",
      "2017-09-04 17:15:51,607 INFO : valid_sample_misclass     0.24228\n",
      "2017-09-04 17:15:51,608 INFO : test_sample_misclass      0.33356\n",
      "2017-09-04 17:15:51,608 INFO : train_misclass            0.14047\n",
      "2017-09-04 17:15:51,609 INFO : valid_misclass            0.14525\n",
      "2017-09-04 17:15:51,610 INFO : test_misclass             0.22500\n",
      "2017-09-04 17:15:51,611 INFO : runtime                   0.69471\n",
      "2017-09-04 17:15:51,611 INFO : \n",
      "2017-09-04 17:15:52,587 INFO : Time only for training updates: 0.69s\n",
      "2017-09-04 17:15:53,385 INFO : Epoch 21\n",
      "2017-09-04 17:15:53,386 INFO : train_loss                0.48517\n",
      "2017-09-04 17:15:53,387 INFO : valid_loss                0.48076\n",
      "2017-09-04 17:15:53,388 INFO : test_loss                 0.62157\n",
      "2017-09-04 17:15:53,389 INFO : train_sample_misclass     0.21284\n",
      "2017-09-04 17:15:53,389 INFO : valid_sample_misclass     0.22256\n",
      "2017-09-04 17:15:53,390 INFO : test_sample_misclass      0.29984\n",
      "2017-09-04 17:15:53,391 INFO : train_misclass            0.15496\n",
      "2017-09-04 17:15:53,392 INFO : valid_misclass            0.15084\n",
      "2017-09-04 17:15:53,392 INFO : test_misclass             0.25625\n",
      "2017-09-04 17:15:53,393 INFO : runtime                   1.79356\n",
      "2017-09-04 17:15:53,394 INFO : \n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We arrive at ca. 80% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to do trialwise decoding instead of cropped decoding, perform the following changes:\n",
    "\n",
    "\n",
    "Change:\n",
    "```python\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = 800\n",
    "in_chans = 3\n",
    "n_classes = 4\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length=30).create_network()\n",
    "```\n",
    "\n",
    "to:\n",
    "```python\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = train_set.X.shape[2]\n",
    "in_chans = 3\n",
    "n_classes = 4\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length='auto').create_network()\n",
    "```\n",
    "\n",
    "Remove:\n",
    "\n",
    "```python\n",
    "to_dense_prediction_model(model)\n",
    "```\n",
    "\n",
    "Remove:\n",
    "\n",
    "\n",
    "```python\n",
    "from braindecode.torch_ext.util import np_to_var\n",
    "# determine output size\n",
    "test_input = np_to_var(np.ones((2, 3, input_time_length, 1), dtype=np.float32))\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "print(\"{:d} predictions per input/trial\".format(n_preds_per_input))\n",
    "```\n",
    "\n",
    "Change:\n",
    "\n",
    "```python\n",
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "iterator = CropsFromTrialsIterator(batch_size=32,input_time_length=input_time_length,\n",
    "                                  n_preds_per_input=n_preds_per_input)\n",
    "```\n",
    "\n",
    "to:\n",
    "\n",
    "```python\n",
    "from braindecode.datautil.iterators import BalancedBatchSizeIterator\n",
    "iterator = BalancedBatchSizeIterator(batch_size=32)\n",
    "```\n",
    "\n",
    "\n",
    "Change:\n",
    "\n",
    "```python\n",
    "loss_function = lambda preds, targets: F.nll_loss(th.mean(preds, dim=2)[:,:,0], targets)\n",
    "```\n",
    "\n",
    "to:\n",
    "\n",
    "```python\n",
    "loss_function = F.nll_loss\n",
    "```\n",
    "\n",
    "Change:\n",
    "\n",
    "```python\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='sample_misclass'),\n",
    "            CroppedTrialMisclassMonitor(input_time_length), RuntimeMonitor(),]\n",
    "```\n",
    "\n",
    "to:\n",
    "\n",
    "```python\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='misclass'), \n",
    "            RuntimeMonitor(),]\n",
    "```\n",
    "\n",
    "Resulting code can be seen at [BBCI Data Epoched](BBCI_Data_Epoched.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
