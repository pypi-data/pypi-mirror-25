""" vimg contains the vImg class, which is the main class in vtools that allows you to represent

"""
####################################################################################################
########################################### vtools.vimg ############################################
############################################# vimg.py ##############################################
####################################################################################################
######################################## Import Statements #########################################


import atexit
from typing import Tuple
from itertools import combinations, compress, product, count

####################################################################################################
####################################### Third Party Imports ########################################

import cv2
import numpy as np
import mahotas as mh

####################################################################################################
########################################## Local Imports ###########################################

from .vtools import eprint, trimPath
from .vcontours import vContour, vContours
from .vhist import vHist
from .types import contour_list_type, color_type, check_odd, nd_or_none, \
                   tuple_or_none, intuple_or_none, str_or_none  # , image_type
from .config import __IDENT__
from .colors import WHITE, BLACK, GREEN, RED, BLUE, AQUA, MAROON, FUCHSIA, OLIVE, NAVY, TEAL, PURPLE, YELLOW
from .colors import vColor

####################################################################################################
########################################### vImg CLASS #############################################


class vImg(np.ndarray):
    """ Initiates a vImg object using np.ndarray as base class. The vImg object extends the array
    to allow for image modification methods to be executed on the base class.
    Parameters:
        :param str imgFn: path to image
        :param  **kwargs: (optional, only color kwarg will be processed if img parameter is supplied)
        img    : numpy np.ndarray class or subclass type
        height : in pixels, height of the blank image
        width  : in pixels, width of the blank image
        color  : in RGB tuple, the bg color for the blank image (default: black)
        title  : string, set the title property for the image object (otherwise
                 this is generated by a sequence generator
        pass   : bool, optional, (default True) works with img parameter. Tells the initialization
                 function to check if img is a vImg. If it is, return it directly.
    """

    COLOR_SPACES = ('RGB', 'BGR', 'HSV', 'LAB')
    _cDict = {'b': 'Blue', 'g': 'Green', 'r': 'Red',
              'L': 'Luminance', 'A': 'Alpha', 'B': 'Beta',
              'h': 'Hue', 's': 'Saturation', 'v': 'Value'}
    ####################################################################################################
    ########################################## DUNDER METHODS ##########################################

    def __new__(cls, imgFN=None, **kwargs):

        def blank(height: int, width: int, color: color_type = BLACK, color_space: str = 'BGR') -> np.ndarray:
            """
                         Creates a blank image
            Parameters:
                height : int, pixel height of the blank image
                width  : int, pixel width of the blank image
                color    : tuple, RGB tuple representing the background color for the blank image
                         (default: black). Remember, in OpenCV rgb values are stored as (B,G,R)
            :param height:
            :param width:
            :param color:
            :param color_space:
            :return:
            """
            if color_space != 'BGR':
                raise ValueError("[-] Invalid argument: BGR must be used to construct blank vImg objects at this time.")
            blank_image = np.zeros((height, width, 3), dtype='uint8')
            color = vColor(color)
            if color != BLACK:
                blank_image[:, :] = color
            return blank_image

        if imgFN is None:
            try:
                if kwargs.get('img', None) is not None:
                    # if the img parameter is provided
                    img = kwargs['img']
                    if kwargs.get('pass', True) and isinstance(img, vImg):
                        return img

                else:
                    # create a blank image using at least the height and width optional parameters
                    img = blank(kwargs['height'], kwargs['width'], kwargs.get('color', BLACK),
                                color_space=kwargs.get('color_space', 'BGR'))

                obj = np.asarray(img).view(cls)
                obj.__h, obj.__w = obj.shape[:2]
                obj.__center = (obj.w // 2, obj.h // 2)
                obj.__color = kwargs.get('color', BLACK)
                obj.__color_space = kwargs.get('color_space', 'BGR')

                return obj

            except KeyError:
                str_err = "KeyError: If 'image' argument not provided, keyword arg(s) for "
                str_err += ('width and height ' if not (kwargs.get('height', None) or kwargs.get('width', None))
                                                   else 'height ' if not kwargs.get('height', None)
                                                   else 'width ' if not kwargs.get('width', None)
                                                   else 'unknown property ')
                str_err += 'must be provided (color is optional).'
                raise ValueError(str_err)

        try:
            obj = np.asarray(cv2.imread(imgFN)).view(cls)
            obj.__imgFN = imgFN
            obj.__h, obj.__w = obj.shape[:2]
        except cv2.error:
            raise ValueError("OpenCV Error occurred.") from None
        except Exception as ex:
            raise ValueError(f"[-] Error: {ex}. Unable to open file {imgFN}.")

        obj.__center = (obj.__w // 2, obj.__h // 2)
        obj.__color_space = kwargs.get('color_space', 'BGR')
        obj.__color = kwargs.get('color', vColor((0, 0, 0)))
        obj.__title = kwargs.get('title', imgFN)
        return obj

    def __array_finalize__(self, obj):
        if obj is None: return
        self.center = getattr(obj, '__center', None)
        self.color = getattr(obj, '__color', None)
        self.color_space = getattr(obj, '__color_space', 'BGR')
        self.__imgFN = getattr(obj, '__imgFN', None)
        self.title = getattr(obj, '__title', None)
        self.__current_title = self.__title

    def __array_wrap__(self, out_arr):
        """__array_wrap__ gets called at the end of numpy ufuncs and
        other numpy functions, to allow a subclass to set the type of
        the return value and update attributes and metadata"""
        out_arr.__center = self.center
        out_arr.__color = self.color
        out_arr.__color_space = self.color_space
        out_arr.__imgFN = self.imgFN
        out_arr.__title = self.title
        out_arr.__current_title = self.__current_title

        return np.ndarray.__array_wrap__(self, out_arr)

    def __eq__(self, other):
        return np.array_equal(self, other)

    def __copy__(self, **kwargs):
        return super().copy(**kwargs).view(vImg)

    def __truediv__(self, other):
        return super().__truediv__(self, other).view(vImg)

    def __repr__(self):
        """ Repr reproduces the expression that created the image object as exactly as possible, a notable
        limitation is that when built using a local path, the object reproduces the local path used.
        May change this behavior in the future to just return the string representation of the image array,
        but this method is usually much more readable and has the same standard as np.ndarray.
        """
        return super().__repr__()

    ####################################################################################################
    ######################################## PRIVATE FUNCTIONS #########################################

    @staticmethod
    def _isOdd(k: check_odd):
        """ Private function that just checks to see if any k_value is passed to a function with
        an even integer value. Instead of raising an exception, I've come here today to write a function
        that tries to automatically correct my stupid mistake that I make repeatedly. That mistake happens
        to be trying to pass a k parameter with an even element (k-boxes need to be odd-dimensioned because they
        affect a center pixel. Even value, no distinct center pixel).
        :param check_odd k: Could be a single k-value or tuple of ints to be checked.
        :return bool: True if both are odd, raises an exception if a number is even.
        """

        k = tuple(k)

        if any(e % 2 == 0 or e < 3 for e in k):
            # Automatically add one to each value if that value is even,
            # or set to three if less than three
            k = [e + 1 if e % 2 == 0
                 else 3 if e < 3
                 else e
                 for e in k]
            # Inform user you have autocorrected his or her innocent mistake (or needlessly
            # caused a type exception.) Why did I write it this way again?
            eprint(f"[-] Must be a tuple of odd integers. Continuing with ({(e for e in k)}), godspeed...")

    ####################################################################################################
    ######################################### IMAGE PROPERTIES #########################################

    @property
    def h(self):
        return self.shape[0]

    @property
    def w(self):
        return self.shape[1]

    @property
    def height(self):
        return self.shape[0]

    @property
    def width(self):
        return self.shape[1]

    @property
    def center(self):
        if self.__center is None:
            self.__center = (self.w // 2, self.h // 2)
        return self.__center

    @center.setter
    def center(self, center_val: tuple_or_none = None):
        self.__center = center_val

    @property
    def color(self):
        return self.__color

    @color.setter
    def color(self, val):
        self.__color = val

    @property
    def color_space(self):
        return self.__color_space

    @color_space.setter
    def color_space(self, color_space: str):
        color_space = color_space.upper()
        if color_space in self.COLOR_SPACES:
            self.__color_space = color_space

    @property
    def imgFN(self):
        return self.__imgFN

    @property
    def title(self):
        return self.__title

    @title.setter
    def title(self, val: str_or_none):
        if val is None and self.__imgFN is not None:
            self.__title = trimPath(self.__imgFN)
        elif hasattr(self, 'title') and self.title is None:
            self.__title = 'img' + next(__IDENT__)
        else:
            self.__title = val

    ####################################################################################################
    ################################### GENERAL TRANSFORMATION TOOLS ###################################
    ###################### Reused very little of Dr. Adrian Rosebrock's code and #######################
    ########################### comments from his excellent package imutils ############################
    #########################  and book 'Practical Python and OpenCV' below.  ##########################

    def BGR2RGB(self):
        rgb_img = cv2.cvtColor(self, cv2.COLOR_BGR2RGB).view(vImg)
        rgb_img.color_space = 'RGB'
        return rgb_img

    def RGB2BGR(self):
        return cv2.cvtColor(self, cv2.COLOR_RGB2BGR).view(vImg)

    def BGR2HSV(self):
        hsv_img = cv2.cvtColor(self, cv2.COLOR_BGR2HSV).view(vImg)
        hsv_img.color_type = 'HSV'
        return hsv_img

    def BGR2LAB(self):
        lab_img = cv2.cvtColor(self, cv2.COLOR_BGR2LAB).view(vImg)
        lab_img.color_type = 'LAB'
        return lab_img

    def gray(self):
        """ function that returns a grayscale transformed from BGR version of the vImg object """
        return cv2.cvtColor(self.copy(), cv2.COLOR_BGR2GRAY).view(vImg)

    def grayHSV(self):
        """ function that returns a grayscale transformed from HSV version of the vImg object """
        return cv2.split(self.BGR2HSV())[2].view(vImg)  # grab the third element (the value channel)

    def translate(self, x: int, y: int):
        """ function that returns translated (shifted by x and y pixels) image
        x : int, number of pixels to move the image horizontally (positive right, negative left)
        y : int, number of pixels to move the image vertically (positive down, negative up)
        """
        # Define the translation matrix and perform the translation
        M = np.float32([[1, 0, x], [0, 1, y]])
        shifted = cv2.warpAffine(self, M, (self.shape[1], self.shape[0])).view(vImg)
        # Return the translated image
        return shifted

    def rotate(self, angle: int = 90, center=None, scale: float = 1.0):
        """ Rotates the image along its axis
        :param angle:
        :param center:
        :param scale:
        :return:
        """

        # Use the image center as the center of rotation if it is not passed as an argument
        if center is None: center = self.center
        # Perform the rotation
        M = cv2.getRotationMatrix2D(center, angle, scale)
        rotated = cv2.warpAffine(self, M, (self.w, self.h)).view(vImg)

        # Return the rotated image
        return rotated

    def resize(self, width=None, height=None, interpolation=cv2.INTER_AREA):
        """ function that returns a resized image based on a given width, height, or both.
        Maintains the aspect ratio of the image if given only one dimension.
        width  : int, optional, width in pixels for the resized image
        height : int, optional, height in pixels for the resized image
        inter  : cv2 CONSTANT, optional, interpolation method
        Valid values for inter:
        cv2.INTER_AREA (default)
        cv2.INTER_NEAREST
        cv2.INTER_CUBIC
        cv2.INTER_LINEAR
        cv2.INTER_LANCZOS4
        """

        # if both the width and height are None, then return the original image
        if width is None and height is None:
            return self

        # initialize the dimensions of the image to be resized and grab the image size
        h, w = self.shape[:2]

        # If width and height are both provided
        if height is not None and width is not None:
            dim = (width, height)

        elif width is None:
            # calculate the ratio of the height and construct the dimensions
            r = height / float(h)
            dim = (int(w * r), height)

        # otherwise, the height is None
        else:
            # calculate the ratio of the width and construct the dimensions
            r = width / float(w)
            dim = (width, int(h * r))

        # resize the image
        resized = cv2.resize(self.copy(), dim, interpolation=interpolation).view(vImg)

        # set the new state and img of the resized img
        return resized

    ####################################################################################################
    ##################################### MORPHOLOGICAL OPERATIONS #####################################

    def erode(self,  iterations: int = 1, k_size: check_odd = (3, 3), k_type: int = cv2.MORPH_RECT):
        """ Performs the erosion morphological operation on the image. Assumes caller is a binary image.
        Erodes the foreground object and makes it smaller.

        :param int   iterations : Number of iterative 'erosions' to perform
        :param check_odd k_size : size of the kernel, first is the width, then height in pixels (both must be odd)
        :param int       k_type : k_type (or kernel type) refers to a the shape of the kernel.
                                  defaults to cv2.MORPH_RECT, could also be cv2.MORPH_CROSS or cv2.MORPH_ELLIPSE
        :return vImg            :
        """

        # Check if k_size is odd.
        self._isOdd(k_size)

        kernel = cv2.getStructuringElement(k_type, k_size).view(vImg)
        erode_img = self.copy()
        return cv2.erode(erode_img, kernel, iterations=iterations).view(vImg)

    def dilate(self,  iterations: int = 1, k_size: check_odd = (3, 3), k_type: int = cv2.MORPH_RECT):
        """ Counter to the erode function, dilate is a morphological operation that results in the foreground pixels
        'growing'. Dilations increase the size of a foreground object and are especially useful for joining broken
        parts of an image together.


        :param int   iterations : Number of iterative 'dilations' to perform
        :param check_odd k_size : size of the kernel, first is the width, then height in pixels (both must be odd)
        :param int       k_type : k_type (or kernel type) refers to a the shape of the kernel.
                                  defaults to cv2.MORPH_RECT, could also be cv2.MORPH_CROSS or cv2.MORPH_ELLIPSE
        :return vImg            :
        """

        # Check if k_size is odd.
        self._isOdd(k_size)

        kernel = cv2.getStructuringElement(k_type, k_size)
        dilate_img = self.copy()
        return cv2.dilate(dilate_img, kernel, iterations=iterations).view(vImg)

    def open(self, k_size: check_odd = (3, 3), k_type: int = cv2.MORPH_RECT):
        """ An opening is an erosion followed by a dilation. Used to remove small undesirable blobs from an image.
        The erosion is applied first to remove the small blobs, then a dilation is applied to regrow the size of the
        original object.

        :param check_odd k_size : size of the kernel, first is the width, then height in pixels (both must be odd)
        :param int       k_type : k_type (or kernel type) refers to a the shape of the kernel.
                                  defaults to cv2.MORPH_RECT, could also be cv2.MORPH_CROSS or cv2.MORPH_ELLIPSE
        :return vImg            :
        """

        # Check if k_size is odd.
        self._isOdd(k_size)

        kernel = cv2.getStructuringElement(k_type, k_size)
        return cv2.morphologyEx(self.copy(), cv2.MORPH_OPEN, kernel).view(vImg)

    def close(self, k_size: check_odd = (3, 3), k_type: int = cv2.MORPH_RECT):
        """ A closing is the opposite of an opening: a dilation followed by an erosion. Typically used to close holes
        inside of objects or for connecting components together. The dilation is applied first to close a hole or
        connect components and is followed by an erosion to restore the original size of the object.

        :param check_odd k_size : size of the kernel, first is the width, then height in pixels (both must be odd)
        :param int       k_type : k_type (or kernel type) refers to a the shape of the kernel.
                                  defaults to cv2.MORPH_RECT, could also be cv2.MORPH_CROSS or cv2.MORPH_ELLIPSE
        :return vImg            :
        """

        # Check if k_size is odd.
        self._isOdd(k_size)

        kernel = cv2.getStructuringElement(k_type, k_size)
        return cv2.morphologyEx(self.copy(), cv2.MORPH_CLOSE, kernel).view(vImg)

    def morphGradient(self, k_size: check_odd = (3, 3), k_type: int = cv2.MORPH_RECT):
        """ The distance between the dilation and erosion, which is useful for determining the outline of an erosion,
        which in turn is useful for determining the outline of a particular object in an image.

        :param check_odd k_size : size of the kernel, first is the width, then height in pixels (both must be odd)
        :param int       k_type : k_type (or kernel type) refers to a the shape of the kernel.
                                  defaults to cv2.MORPH_RECT, could also be cv2.MORPH_CROSS or cv2.MORPH_ELLIPSE
        :return vImg            :
        """

        # Check if k_size is odd.
        self._isOdd(k_size)

        kernel = cv2.getStructuringElement(k_type, k_size)
        return cv2.morphologyEx(self.copy(), cv2.MORPH_GRADIENT, kernel).view(vImg)

    def blackHat(self, k_size: check_odd = (3, 3), k_type: int = cv2.MORPH_RECT):
        """ The black hat operation is the difference between the closing operation and the original image,
        which is the opposite of the top hat operation. Black hat and Top hat MOs are best used on grayscale images.
        Black hat operations are typically used to reveal dark regions of an image on a bright (or white) background.

        :param check_odd k_size : size of the kernel, first is the width, then height in pixels (both must be odd)
        :param int       k_type : k_type (or kernel type) refers to a the shape of the kernel.
                                  defaults to cv2.MORPH_RECT, could also be cv2.MORPH_CROSS or cv2.MORPH_ELLIPSE
        :return vImg            :
        """

        # Check if k_size is odd.
        self._isOdd(k_size)

        kernel = cv2.getStructuringElement(k_type, k_size)
        return cv2.morphologyEx(self.copy(), cv2.MORPH_BLACKHAT, kernel).view(vImg)

    def topHat(self, k_size: check_odd = (3, 3), k_type: int = cv2.MORPH_RECT):
        """ The white hat operation returns the difference between the original image and the opening MO. Top hat and
        black hat MOs are best used on grayscale images. Top hat operations are typically used to reveal bright
        regions of an image on dark backgrounds.

        :param check_odd k_size : size of the kernel, first is the width, then height in pixels (both must be odd)
        :param int       k_type : k_type (or kernel type) refers to a the shape of the kernel.
                                  defaults to cv2.MORPH_RECT, could also be cv2.MORPH_CROSS or cv2.MORPH_ELLIPSE
        :return vImg            :
        """

        # Check if k_size is odd.
        self._isOdd(k_size)

        kernel = cv2.getStructuringElement(k_type, k_size)
        return cv2.morphologyEx(self.copy(), cv2.MORPH_TOPHAT, kernel).view(vImg)

    ####################################################################################################
    ########################################## BLURRING TOOLS ##########################################

    def blur(self, k_size: check_odd = (5, 5)):
        """ blur takes some input and returns a Average Blurred version of the image.
        The average blurring process is so named because we take a box called a "convolution
        kernel" of k x k pixels. Starting at one corner of the image, it slides left to right
        and up to down one pixel at a time, each time it moves calculating the average of all
        pixel intensities inside the kernel, then replacing the value of the central pixel in
        the kernel in the output image with the computed average.

        :param tuple k_size: tuple(2int) size of the kernel used in calculating the pixel
                                  intensity average. Must be a tuple of two odd integers
        :return vImg            : The new blurred image
        """

        # Check if k_size is odd.
        self._isOdd(k_size)

        return cv2.blur(self.copy(), k_size).view(vImg)

    def GaussianBlur(self, k_size: check_odd = (5, 5), sigma: int = 0):
        """ GuassianBlur takes some input and returns a Gaussian Blurred version of the image.
        Gaussian blurring is similar to average blurring, but the nearer the pixel is to
        the kernel's center, to the greater the weight that is applied to that pixel's value.

        Gaussian Blur is effective at mitigating noise in high frequency edges and eliminating
        noise that follows a gaussian distribution.

        :param tuple  k_size: tuple(2int) size of the kernel used in calculating the pixel
                              intensity average. Must be a tuple of two odd integers
        :param        sigma: The standard deviation in the x-axis direction. By setting
                             this value to zero (or leaving it default), OpenCV will
                             automatically calculate sigma based on kernel size.
        :return vImg       : The new blurred image
        """

        # Check if k_size is odd.
        self._isOdd(k_size)

        return cv2.GaussianBlur(self.copy(), k_size, sigma).view(vImg)

    ####################################################################################################
    ######################################## THRESHOLDING TOOLS ########################################

    def threshold(self, T: int, k: int = 5, inverse: bool = True):
        """ We will apply binary thresholding from the current image object and return the second result
        i.e. the threshold map. This method is very basic and requires manual tuning of the T value for each
        image in order to obtain usable results.
        T : int, threshold pixel intensity
        k : kernel size in square pixels for gaussian blur, default to 5
        inverse: bool, whether or not to return an inverse binary threashold, default YES
        """
        # Confirm that k is odd
        self._isOdd(k)

        # Check if the image is black and white, if it isn't, convert it
        image = self
        if len(self.shape) > 2:
            image = self.gray()

        # First, apply a gaussian blur
        gauss = image.GaussianBlur((k, k), 0)

        # Next, apply the threshold to the image
        thresh_bin = cv2.THRESH_BINARY_INV if inverse is True else cv2.THRESH_BINARY
        thresh = cv2.threshold(gauss, T, 255, thresh_bin)[1]

        # Finally, return the result
        return thresh.view(vImg)

    def adaptiveThreshold(self, adaptive_method=cv2.ADAPTIVE_THRESH_GAUSSIAN_C, neighborhood=25, k=5,
                          C=2, inverse=True):
        """ Applies adaptive thresholding to the image object and return a threshold map based off of a
        given neighborhood size.
        :param int adaptive_method : cv2 constant that represents which adaptive thresholding method we will
                                     use (e.g. cv2.ADAPTIVE_THRESH_MEAN_C, cv2.ADAPTIVE_THRESH_GAUSSIAN_C)
        :param int    neighborhood : default 25, size of the neighborhood in which to evaluate small areas
                                     of pixels in order to find an optimal value of T to apply thresholding
        :param int               k : kernel size in square pixels for gaussian blur, default to 5
        :param int               C : subtracted from the mean, giving us granular control of the adaptive
                                     thresholding process, default to 0
        :param bool        inverse : bool, value representing whether or not the threshold constant used will
                                     be inverse or normal. Inverse is default since it's commonly used for
                                     masking.
        """
        # Confirm that k is odd
        self._isOdd(k)

        # First, assert the color of the image is grayscale, then apply a gaussian blur
        assert len(self.shape) == 2, "Must use on grayscale image"
        gauss = cv2.GaussianBlur(self, (k, k), 0)

        # determine whether to use standard or inverse binarization method
        thresh_bin = cv2.THRESH_BINARY if not inverse else cv2.THRESH_BINARY_INV

        # Next, apply the threshold to the image
        thresh = cv2.adaptiveThreshold(gauss, 255, adaptive_method, thresh_bin, neighborhood, C)

        # Return the new vImg object
        return vImg(img=thresh)

    ####################################################################################################
    ########################################## DRAWING TOOLS ###########################################
    # TODO: Add functions for drawing lines and other shapes

    ####################################################################################################
    ######################################## EDGE MAPPING TOOLS ########################################

    def Laplacian(self):
        """Performed on a grayscale image, returns the Laplacian gradient of the image.
        :return: 
        :rtype: vImg
        """
        lap = cv2.Laplacian(self, cv2.CV_64F)
        # lap = np.uint8(np.absolute(lap))
        return np.asarray(np.absolute(lap)).astype('u1').view(vImg)
        # return vImg(img=lap)

    def SobelX(self):
        """Performed on a grayscale image, returns the Sobel gradient image along the X axis
        :return: 
        :rtype: vImg
        """
        # Calculate the Sobel gradient along the X-axis
        return cv2.Sobel(self, cv2.CV_64F, 1, 0).view(vImg)

    def SobelY(self):
        """Performed on a grayscale image, returns the Sobel gradient image along the Y axis
        :return: 
        :rtype: vImg
        """
        # Calculate the Sobel gradient along the Y-axis
        return cv2.Sobel(self, cv2.CV_64F, 0, 1).view(vImg)

    def SobelCombined(self):
        """Performed on a grayscale image, returns the Sobel gradient image along both axes.
        :return: 
        :rtype: vImg
        """

        # Calculate the Sobel gradient along the X-axis
        sobelX = cv2.Sobel(self, cv2.CV_64F, 1, 0)
        # Calculate the Sobel gradient along the Y-axis
        sobelY = cv2.Sobel(self, cv2.CV_64F, 0, 1)

        # Perform bitwise or calculation
        return cv2.bitwise_or(sobelX, sobelY).view(vImg)

    def autoCanny(self, sigma: float = 0.33):
        # compute the median of the single channel pixel intensities
        v = float(np.median(self))

        # apply automatic Canny edge detection using the computed median
        lower = int(max(0., (1.0 - sigma) * v))
        upper = int(min(255., (1.0 + sigma) * v))

        # return the edged image
        return cv2.Canny(self, lower, upper).view(vImg)

    ####################################################################################################
    ########################################## CONTOUR TOOLS ###########################################

    def drawContours(self, contours: contour_list_type, index: int = -1, color: color_type = GREEN,
                     thickness: int = -1):
        """

        :param contour_list_type contours: List of contours
        :param int                  index: default -1 (all indexes), index of the contours list argument that you
                                           would like to draw
        :param color_type           color: default GREEN, BGR tuple of three integers representing the desired color
        :param int              thickness: default -1 (solid), border width of the contour to draw on the image
        :return                      vImg: returns new vImg object with requested contours drawn on it
        """
        img = self.copy()
        cv2.drawContours(img, contours, index, color, thickness)
        return vImg(img=img)

    def simpleContours(self, quantity=cv2.RETR_EXTERNAL, complexity=cv2.CHAIN_APPROX_SIMPLE):
        """Performs simple cv2.findContours operation using common but overridable default 
           parameters on a vImg object, returns a list of vContour
        
        quantity    : cv2.RETR_EXTERNAL (default), also could be: cv2.RETR_LIST, cv2.RETR_COMP, 
                      and cv2.RETR_TREE
        complexity  : cv2.CHAIN_APPROX_SIMPLE (default), also could be: cv2.CHAIN_APPROX_NONE
        
        Passes the second element returned from cv2.findContours to the vContour class's fromList
        builder. Returns a vContours list of vContour objects. 
        
        Returns the 2nd element because the first element returned by cv2.findContours is 
        a 'destroyed' version of the image passed to it.
        """
        try:
            return vContour.fromList(cv2.findContours(self.copy(), quantity, complexity)[1])
        except cv2.error:
            eprint("\nOpenCV Error: likely tried to use image that has not been thresholded. \n"
                   "Now attempting to continue this operation using autoCanny(). \n"
                   "To avoid this error message, pass only edge maps to the simpleContours() function,\n"
                   "e.g. vImg('test.png').autoCanny().simpleContours()\n")
            return vContour.fromList(cv2.findContours(self.autoCanny(), quantity, complexity)[1])

    def evalContours(self, cnts=None, count=None, reverse=True, outline_color=GREEN, font_color=RED):
        """This function exists to make it easier to evaluate contours in an image. Calling this
        function and supplying a list of contours iterates through the list of contours and
        identifies them one at a time on the image while simultaneously displaying useful
        simple and advanced contour properties in the console.
        
        Very useful for determining if contour analysis may be used effectively in a given 
        application. Not generally applicable or useful in a production environment.
        
        cnts          : vContours object (list of vContour), use the simpleContours method to 
                        easily generate a vContours object
        count         : int, if supplied, the contours will be sorted and count will determine 
                        how many are returned
        reversed      : bool, defaults to False, if set True when called, contours will be 
                        size-sorted in reverse (big to small) before being truncated to count 
                        number of contours.
        outline_color : tuple (3 unsigned 8-bit integers), 3-tuple indicating color of outline 
                        in RGB format
        font_color    : tuple (3 unsigned 8-bit integers), 3-tuple indicating color of label 
                        text in RGB format
        """

        if cnts is None:
            cnts = self.simpleContours()

        assert isinstance(cnts, vContours), 'Must be vContours iterable'

        if count is not None:
            cnts.sizeSort(reverse=reverse)
            cnts = cnts[:count]

        if not isinstance(outline_color, vColor):
            outline_color = vColor(outline_color)

        if not isinstance(font_color, vColor):
            font_color = vColor(font_color)

        img = self.copy()

        for i, c in enumerate(cnts):
            cv2.drawContours(img, [c], -1, outline_color.BGR, 3)
            cv2.putText(img, f'#{i}', (c.x, c.y - 5), cv2.FONT_HERSHEY_SIMPLEX,
                        0.5, font_color.BGR, 2)
            print(f"""Shape #{i} @ x({c.x},{c.x2}) y({c.y}, {c.y2})
            --------------------------------------------------------------
            width: {c.width} height: {c.height}
            Aspect Ratio is (image width / image height): {c.aspect_ratio:.2f}
            Contour Area is: {c.area:.2f}
            Bounding Box Area is: {c.w * c.h:.2f}
            Convex Hull Area is: {c.hull_area:.2f}
            Solidity (Contour Area / Convex Hull Area) is: {c.solidity:.2f} 
            Extent (Contour Area / Bounding Box Area) is: {c.extent:.2f}
            Center is located at: {c.center}""")
            cv2.imshow(self.title, img)
            cv2.waitKey(0)
        atexit.register(cv2.destroyAllWindows)

    ####################################################################################################
    ######################################### HISTOGRAM TOOLS ##########################################
    def histogram(self,
                  hist_type: str = '1D',
                  channels: tuple = (False,) * 3,
                  mask: nd_or_none = None,
                  bins: intuple_or_none = None,
                  xlimit: intuple_or_none = None,
                  normal: bool = False,
                  display: bool = False,
                  legend: bool = True):
        """ The histogram function is used to return a vHists object that represents the histogram as desired
        :param   hist_type : '1D' - Flat histogram, '2D' - two-dimensional hist, or '3D' - three-dimensional hist
        :param    channels : 3-tuple of boolean values, representing which channels to include in the histogram
        :param        mask : can be of type np.ndarray or a subclass (vImg), mask to hide segments of the provided
                             image up on calculation of the histogram
        :param        bins : number of possible 'buckets' in which to place pixel values
        :param      xlimit : the x-limit of the resulting histogram
        :param      normal : flag parameter for whether the histogram is to be normalized
        :param     display : whether the method should display** the resulting histogram
                             ** not implemented for 3D histograms
        :param      legend : flag parameter for whether or not a legend is shown, default is True
        :return            : vHist object
        """

        # First, ensure that  hist_type params are in all caps for the conditional comparisons
        # that will be performed each time
        # Check for supported color space parameter
        if self.color_space not in self.COLOR_SPACES:
            raise ValueError(f"[-] Fatal Error: {self.color_space} not in ({', '.join(self.COLOR_SPACES)}).")

        # Second, we must do the same for the histogram type (hist_type)
        hist_type = hist_type.upper()
        # Check for supported color space parameter
        HIST_TYPES = ('1D', '2D', '3D')
        if hist_type not in HIST_TYPES:
            raise ValueError(f"[-] Fatal Error: {hist_type} not in supported hist types: ({', '.join(HIST_TYPES)}).")

        # set number of allowable channels dict based on channels tuple
        # Assuming it's faster to hard code than generate/iterate
        # itertools.product((True,False), repeat=3) every histogram
        channel_product = ((True, True, True), (True, True, False), (True, False, True),
                           (True, False, False), (False, True, True), (False, True, False),
                           (False, False, True), (False, False, False))

        if channels not in channel_product:
            raise ValueError(f"[-] Fatal Error: channels must be a tuple of three bool values representing " 
                              "color channel inclusion (e.g. (False, False, False) for black and white, or " 
                              "(True, True, False) for B and G channel inclusion, etc.).")

        # set default bins behavior based on hist_type and self.color_space
        if bins is None:
            BINS_DICT = {
                ('1D', 'BGR'): (256,),
                ('1D', 'HSV'): (256,) if channels != (True, False, False) else (181,),
                ('1D', 'LAB'): (256,) if channels != (True, False, False) else (101,),
                ('2D', 'BGR'): (32, 32),
                ('2D', 'HSV'): (32, 32),
                ('2D', 'LAB'): (32, 32),
                ('3D', 'BGR'): (8, 8, 8),
                ('3D', 'HSV'): (8, 8, 8),
                ('3D', 'LAB'): (8, 8, 8),
            }
            bins = BINS_DICT[(hist_type, self.color_space)]

        # set default xlimit behavior based on hist_type and self.color_space
        if xlimit is None:
            XLIMIT_DICT = {
                ('1D', 'BGR'): (0, 256),
                ('1D', 'HSV'): (0, 256) if channels != (True, False, False) else (0, 181),
                ('1D', 'LAB'): (0, 256) if channels != (True, False, False) else (0, 101),
                ('2D', 'BGR'): (0, 256, 0, 256),
                ('2D', 'HSV'): (0, 256, 0, 256) if channels == (False, True, True) else (0, 181, 0, 256),
                ('2D', 'LAB'): (0, 256, 0, 256) if channels == (False, True, True) else (0, 101, 0, 256),
                ('3D', 'BGR'): (0, 256, 0, 256, 0, 256),
                ('3D', 'HSV'): (0, 181, 0, 256, 0, 256),
                ('3D', 'LAB'): (0, 101, 0, 256, 0, 256),
            }
            xlimit = XLIMIT_DICT[(hist_type, self.color_space)]

        # Handle 3D histograms first, since they're easier and we aren't worried about visualization
        if hist_type == '3D':
            hist = cv2.calcHist([self], [0, 1, 2], mask, bins, xlimit)
            if normal:
                hist /= hist.sum()
            return vHist(hist, self.title, color_space=self.color_space, hist_type='3D')

        image = None

        # Convert to grayscale image if all three (3) channels are False and the image currently has color
        if hist_type == '1D' and channels == (False,) * 3:
            if len(self.shape) > 2:
                # First, convert the image to grayscale
                image = self.gray()
            else:
                image = self
            # Calculate the 1-dimensional grayscale histogram
            hist = cv2.calcHist([image], [0], mask, bins, xlimit)
            # Create the vHist
            hist = vHist(hist, self.title, color_space=self.color_space, hist_type='1D')

            # Create a histogram parameter dict that we will unpack as args to vHist show function
            # ... and change the y_title parameter to reflect normalization
            show_params = {'title': f"1D Color Hist ({self.title})",
                           'x_title': 'Bins',
                           'y_title': '# of Pixels' if not normal else 'Percentage of Pixels',
                           'legend': legend
                           }

            # If the normalization parameter is True, perform the histogram normalization
            if normal:
                hist /= hist.sum()

            # If display parameter is True, plot the histogram
            if display:
                hist.show(**show_params)

            # ... and return the vHist object
            return (('k', hist),)

        # if 1-dimensional (flat) histogram is requested
        elif hist_type == '1D' and self.shape[2] == 3:
            # split the image into its separate 2-dimensional matrices for each channel
            # split_image = cv2.split(image)

            # Create local color_space variable, tuple with 3 letters representing the
            # channel names of the image. Leave LAB as capitalized due to the overlap of the
            # letter B in BGR and LAB (so self.__cDict can return an accurate channel name
            # from a single letter)
            color_space = self.color_space.lower() if self.color_space != 'LAB' else 'LAB'

            single_channel_dict = {
                0: (True, False, False),
                1: (False, True, False),
                2: (False, False, True),
            }

            # create a zipped/enumerated/compressed tuple with each channel and its color identifier
            # if the channels parameter tuple is marked True for that color.
            # Ex.: channels (False, True, True) -> ((1, 'b'), (2, 'g'))
            # Result: ((the channel # [0-2], bool representing if the channel is included),)
            cczip = tuple(compress(enumerate(color_space), channels))

            # initialize results
            results = tuple()

            # loop over each (image channel, color) tuple in each
            for i, clr in cczip:
                hist = cv2.calcHist([self], [i], mask, bins, xlimit)
                if normal: hist /= hist.sum()
                hist = vHist(hist, self.title, color_space=self.color_space, hist_type='1D',
                             channels=single_channel_dict[i])
                results += ((clr, hist),)

            if display is False:
                return results

            # Create a histogram parameter dict that will provide the vHist show function with the proper parameters
            # for the y_title according to whether the histogram is normalized
            # If histogram is normalized, change the y-axis to reflect the correct title
            show_params = {
                           'x_title': 'Bins',
                           'y_title': 'Percentage (%) of Pixels' if normal else
                                      '# of Pixels',
                           'legend': legend
                          }

            # _and() is a small helper function for setting plot_title. Returns an ' and ' for the
            # final color channel if the length of cczip is greater than one or '' if not
            def _and(): return ' and ' if len(cczip) > 1 else ''

            # set the title according to the number of results in our flat histogram
            # unpack the channel names using cDict and join them using a combination
            # of f-strings, join, and conditional functions.

            *chans, final_chan = [self._cDict[e[1]] for e in cczip]

            plot_title = f"Flattened Color Histogram Title: ({self.title})\n" \
                         f"Channel(s): {', '.join(e for e in chans)}{_and()}{final_chan}."

            show_params['title'] = plot_title
            show_params['append'] = results[1:]

            results[0][1].show(**show_params)
            return results

        elif hist_type == '2D':

            color_space = self.color_space.lower() if self.color_space != 'LAB' else self.color_space

            chans = cv2.split(self)
            # create a list that contains each color that needs to be tested, a string representation
            # of that color, and a bool representing whether that color is included, filter out False
            # ((i0, channeldata0, color0), (i1, channeldata1, color1), (i2, channeldata2, color2))
            cczip = tuple(compress(zip(range(3), chans, color_space), channels))

            # Create generator for all unique combinations of colors that are included
            channels = combinations(((i, chan, color) for i, chan, color in cczip), 2)

            i = 0
            results = tuple()
            # loop through the possible combinations of 2-channel histograms created by cczip and create a vHist
            # for each pair
            for (i, chan1, color1), (j, chan2, color2) in channels:
                hist = cv2.calcHist([chan1, chan2], [0, 1], mask, bins, xlimit)
                hist_title = f"2D Color Histogram for {self.__cDict[color1]} and {self.__cDict[color2]} ({self.title})"

                # Create a tuple representing the current active channels (0 - 2) are active in the current
                # two-dimensional histogram. For example if the current 2-D hist is comparing channels 0 and 2,
                # then active_chans == (True, False, True)
                active_chans = tuple((x == i or x == j) for x in range(3))

                hist = vHist(hist, self.title, color_space=self.color_space, hist_type='2D', channels=active_chans)

                results += ((active_chans, hist, hist_title),)

            # results[0][2] will be the hist_title variable for the first result
            show_params = {
                           'title': results[0][2],
                           'append': results[1:],
                           'legend': legend
                          }
            if display:
                results[0][1].show(**show_params)

            return results

    ####################################################################################################
    ####################################### MASKING AND CROPPING #######################################

    def blankMask(self, zeros: bool = True):
        """ Return a blank 1-channel mask the size of the original image."""
        return np.zeros(self.shape[:2], dtype="uint8") if zeros is True \
               else np.ones(self.shape[:2], dtype="uint8") * 255

    def vContoursMask(self, cnts: vContours, index: int = -1, value: int = 255, thickness: int = -1):
        """ Creates a mask from a list of vContours,

        :param vContours   cnts: Parent image used to create mask from contours
        :param int        index: Default -1 (all), optionally provide a specific contour for the mask
        :param int        value: Default 255, optionally override the pixel mask value
        :param int    thickness: Default -1 (solid), optionally return mask of given thickness around contour
        :return            vImg: Returns a vImg
        """

        # Create blank mask
        mask = self.blankMask()

        # Call draw contours to create the mask from the vContours list
        cv2.drawContours(mask, cnts, index, value, thickness)

        return vImg(img=mask)

    def roi(self, c: vContour):
        """ returns a slice of an image corresponding to a vContour's x, y, w, and h properties
        :param vContour    c: vContour on which to base the dimensions of the returned cropped image
        :return vImg        : vImg cropped to the boundaries of the vContour passed to it
        """

        assert isinstance(c, vContour), 'Must be vContour.'

        try:
            return self[c.y:c.y2, c.x:c.x2]

        except IndexError:
            eprint('[-] IndexError: are you sure this contour belongs to this image?')

    ####################################################################################################
    ######################################## FEATURE EXTRACTORS ########################################

    def moments(self):
        return cv2.moments(self).flatten()

    def HuMoments(self):
        """ Returns the Hu Moments calculated by the opencv library in the form of a flattened
        list of seven moments.
        """
        return cv2.HuMoments(cv2.moments(self)).flatten()

    def ZernikeMoments(self, radius, degree=8, center_of_mass=None):
        """
        Copyright (C) 2006-2014, Luis Pedro Coelho <luis@luispedro.org>
        License: MIT

        zvalues = zernike_moments(im, radius, degree=8, cm={center_of_mass(im)})
        Zernike moments through ``degree``. These are computed on a circle of
        radius ``radius`` centered around ``cm`` (or the center of mass of the
        image, if the ``cm`` argument is not used).
        Returns a vector of absolute Zernike moments through ``degree`` for the
        image ``im``.
        Parameters
        ----------
        radius : integer
            the maximum radius for the Zernike polynomials, in pixels. Note that
            the area outside the circle (centered on center of mass) defined by
            this radius is ignored.
        degree : integer, optional
            Maximum degree to use (default: 8)
        cm : pair of floats, optional
            the centre of mass to use. By default, uses the image's centre of mass.
        Returns
        -------
        zvalues : 1-ndarray of floats
            Zernike moments
        References
        ----------
        Teague, MR. (1980). Image Analysis via the General Theory of Moments.  J.
        Opt. Soc. Am. 70(8):920-930.
        """
        if not center_of_mass:
            return mh.features.zernike_moments(self, radius, degree)

        else:
            return mh.features.zernike_moments(self, radius, degree, center_of_mass)

    def HaralickTexture(self, *args, **kwargs):
        """ A feature vector that attempts to quantify the texture of a given image.

        :param self:
        :return:
        """
        image = self.copy()
        return mh.features.haralick(image, *args, **kwargs)

    ####################################################################################################
    ###################################### OBJECT DETECTION TOOLS ######################################

    def connectedComponents(self, connectivity: int = 8, type=cv2.CV_32S):
        """ Perform connected component analysis and return a matrix of labels corresponding
        to the found objects in the analyzed image. 0 represents background, while integers 
        above zero correspond to the label of a single found object.
                
        :param connectivity : int, 8 or 4 for 8-way or 4-way connectivity, respectively
        :param type         : Currently CV_32S and CV_16U are supported.
        :return             : mat of labels corresponding to the found components
        """

        return cv2.connectedComponents(self, connectivity, type)[1]  # only return the label matrix

    def pyramid(self, scale: float = 1.5, min_size: Tuple[int, int] = (64, 64)):
        """ Generator that returns successively smaller versions of an image object until a supplied
        minimum size is reached.
        :param scale    : float, The denominator by which the width of the image is successively divided.
        :param min_size : 2-tuple of integers, (minY, minX), minimum dimensions for the image, if the 
                          image is made smaller than these supplied dimensions the generator ends.
        :return         : yields successively smaller images until a minimum is reached, based on the
                          supplied parameters.
        """
        # yield the original self
        yield self

        # need the following line to make sure self doesn't refer to the original object's state,
        # which results in an infinite loop
        image = self

        # separate the values from min_size for clarity
        minX, minY = min_size

        # keep looping over the pyramid
        while True:
            # compute the new dimensions of the self and resize it
            w = int(image.w / scale)

            # the following line always resizes from the original object (self) to avoid a
            # recursive reduction in quality. w always gets smaller so image also gets
            # successively reduced in size.
            image = self.resize(width=w)

            # if the resized image becomes smaller than the supplied minimum allowed
            # size, then stop constructing the pyramid
            if image.h < minY or image.w < minX:
                return

            # yield the next image in the pyramid
            yield image

    def slidingWindow(self, step_size: int = 32, window_size: Tuple[int, int] = (64, 64)):
        """ Returns a "sliding window" as it slides across the image, yielding the current frame at
        iterations specified by the step_size and window_size parameters.
        :param int                step_size : number of pixels the window will move by as it
        :param Tuple[int]       window_size :
        :return:
        """

        yield from ((x, y, self[y:y + window_size[1], x:x + window_size[0]])
                    for y in range(0, self.h, step_size)
                    for x in range(0, self.w, step_size))

    def slidingWindowPyramid(self, scale=1.5, min_size=(64, 64), step_size=32, window_size=(64, 64)):
        """ Returns a sliding window chained with the pyramid function. The results is a sliding window
        that slides across the image and then repeats with successively smaller versions of the image.
        
        :param scale       : float, The denominator by which the width of the image is successively divided.
        :param min_size    : 2-tuple of integers, (minY, minX), minimum dimensions for the image, if the
                             image is made smaller than these supplied dimensions the generator ends.
        :param step_size   : 
        :param window_size : 
        :return            : 
        """

        yield from ((x, y, window, layer) for layer in self.pyramid(scale, min_size)
                    for x, y, window in layer.slidingWindow(step_size, window_size))

    ####################################################################################################
    ####################################### IMAGE DISPLAY TOOLS ########################################

    def show(self, title: str_or_none = None, wait=0, waitKey=True, destroy=True):
        """ Display the image using opencv's imshow functions. Also optionally follows that command
        up with the waitKey function with an optionally provided wait time. Always registers the
        cv2.destroyAllWindows function to run at program exit to ensure cleanup.
        
        :param str    title : Optional, string, represents an optionally provided custom title for the window
                              in which the image is displayed. If this is not provided, the image's title
                              property is used for the window instead. Does not set the title.
        :param int     wait : Optional, int (default is 0), represents the number of seconds provided to the
                              cv2.waitKey function.
        :param bool waitKey : Optional, bool (default is True), set this parameter to False to disable invoking
                              the cv2.waitKey function.
        :param bool destroy : Optional, bool (default is True), set this parameter to False to disable registering
                              cv2.destroyAllWindows at program exit.
        """
        # TODO: Any negative effects from using atexit functionality to always run cv2.destroyAllWindows()?

        if title is None:
            title = self.title

        self.__current_title = title

        cv2.imshow(title, self)

        if waitKey:
            cv2.waitKey(wait)

        if destroy:
            atexit.register(cv2.destroyAllWindows)

    def putText(self, text, loc, font=cv2.FONT_HERSHEY_SIMPLEX, font_scale=1.0, color=GREEN,
                thickness=2, line_type=None, copy=True):
        """

        :param str         text :
        :param tuple        loc :
        :param int         font :
        :param float font_scale :
        :param vColor     color :
        :param int    thickness :
        :param        line_type :
        :param bool        copy :
        :return                 :
        """

        result = None

        if copy is True:
            result = vImg(img=cv2.putText(self, f"{text}", loc, font, font_scale, color, thickness))

        else:
            cv2.putText(self, f"{text}", loc, font, font_scale, color, thickness)

        return result

    def hide(self):
        """ Attempt to kill a currently open image """
        try:
            cv2.destroyWindow(self.__current_title)

        except cv2.error:
            eprint('[+] OpenCv Error prevented closing of requested window.')
